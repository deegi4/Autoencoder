{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "# this is the size of our encoded representations\n",
    "encoding_dim = 32  # 32 floats -> compression of factor 24.5, assuming the input is 784 floats\n",
    "\n",
    "# this is our input placeholder\n",
    "input_img = Input(shape=(784,))\n",
    "# \"encoded\" is the encoded representation of the input\n",
    "encoded = Dense(encoding_dim, activation='relu')(input_img)\n",
    "# \"decoded\" is the lossy reconstruction of the input\n",
    "decoded = Dense(784, activation='sigmoid')(encoded)\n",
    "\n",
    "# this model maps an input to its reconstruction\n",
    "autoencoder = Model(input_img, decoded)\n",
    "\n",
    "# this model maps an input to its encoded representation\n",
    "encoder = Model(input_img, encoded)\n",
    "\n",
    "# create a placeholder for an encoded (32-dimensional) input\n",
    "encoded_input = Input(shape=(encoding_dim,))\n",
    "# retrieve the last layer of the autoencoder model\n",
    "decoder_layer = autoencoder.layers[-1]\n",
    "# create the decoder model\n",
    "decoder = Model(encoded_input, decoder_layer(encoded_input))\n",
    "\n",
    "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')\n",
    "print('end')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading images...\n",
      "['3' '2' '2' '2' '0' '2' '2' '0' '1' '1' '2' '1' '0' '3' '1' '1' '0' '0'\n",
      " '1' '2' '2' '2' '2' '1' '0' '3' '2' '1' '3' '3' '1' '1' '3' '0' '3' '1'\n",
      " '0' '3' '1' '0' '3' '0' '2' '0' '0' '3' '3' '3' '3' '0' '2' '1' '2' '0'\n",
      " '3' '3' '2' '1' '1']\n",
      "end\n"
     ]
    }
   ],
   "source": [
    "# set the matplotlib backend so figures can be saved in the background\n",
    "# import matplotlib\n",
    "# matplotlib.use(\"Agg\")\n",
    " \n",
    "# import the necessary packages\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam\n",
    "# from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.utils import to_categorical\n",
    "# from pyimagesearch.lenet import LeNet\n",
    "from imutils import paths\n",
    "# import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import argparse\n",
    "import random\n",
    "import cv2\n",
    "import os\n",
    "# from keras.datasets import mnist\n",
    "# import numpy as np\n",
    "\n",
    "# initialize the data and labels\n",
    "print(\"[INFO] loading images...\")\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "# grab the image paths and randomly shuffle them\n",
    "imagePaths = sorted(list(paths.list_images('photos')))\n",
    "random.seed(13)\n",
    "random.shuffle(imagePaths)\n",
    "# print(imagePaths)\n",
    "\n",
    "# loop over the input images\n",
    "for imagePath in imagePaths:\n",
    "\t# print(imagePath)\n",
    "\t# load the image, pre-process it, and store it in the data list\n",
    "\timage = cv2.imread(imagePath)\n",
    "\timage = cv2.cvtColor( image, cv2.COLOR_RGB2GRAY )\n",
    "\timage = cv2.resize(image, (28, 28))\n",
    "\timage = img_to_array(image)\n",
    "\tdata.append(image)\n",
    "\n",
    "\t# extract the class label from the image path and update the\n",
    "\t# labels list\n",
    "\tlabel = imagePath.split(os.path.sep)[-2]\n",
    "\t# label = 1 if label == \"santa\" else 0\n",
    "\tlabels.append(label)\n",
    "    \n",
    "\n",
    "# scale the raw pixel intensities to the range [0, 1]\n",
    "# data = np.array(data, dtype=\"float\") / 255.0\n",
    "\n",
    "# data = np.array(data, dtype=\"float32\") / 255\n",
    "\n",
    "x_train = np.array(data, dtype=\"float\") / 255.0\n",
    "x_test = np.array(data, dtype=\"float\") / 255.0\n",
    "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
    "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
    "labels = np.array(labels)\n",
    "# Y_train = np_utils.to_categorical(labels, 4)\n",
    "\n",
    "print(labels)\n",
    "\n",
    "print('end')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 59 samples, validate on 59 samples\n",
      "Epoch 1/1000\n",
      "59/59 [==============================] - 1s 18ms/step - loss: 0.6945 - val_loss: 0.6938\n",
      "Epoch 2/1000\n",
      "59/59 [==============================] - 0s 898us/step - loss: 0.6936 - val_loss: 0.6931\n",
      "Epoch 3/1000\n",
      "59/59 [==============================] - 0s 831us/step - loss: 0.6930 - val_loss: 0.6926\n",
      "Epoch 4/1000\n",
      "59/59 [==============================] - 0s 915us/step - loss: 0.6925 - val_loss: 0.6922\n",
      "Epoch 5/1000\n",
      "59/59 [==============================] - 0s 1ms/step - loss: 0.6921 - val_loss: 0.6918\n",
      "Epoch 6/1000\n",
      "59/59 [==============================] - 0s 864us/step - loss: 0.6917 - val_loss: 0.6915\n",
      "Epoch 7/1000\n",
      "59/59 [==============================] - 0s 932us/step - loss: 0.6914 - val_loss: 0.6911\n",
      "Epoch 8/1000\n",
      "59/59 [==============================] - 0s 881us/step - loss: 0.6910 - val_loss: 0.6908\n",
      "Epoch 9/1000\n",
      "59/59 [==============================] - 0s 831us/step - loss: 0.6907 - val_loss: 0.6904\n",
      "Epoch 10/1000\n",
      "59/59 [==============================] - 0s 729us/step - loss: 0.6903 - val_loss: 0.6900\n",
      "Epoch 11/1000\n",
      "59/59 [==============================] - 0s 881us/step - loss: 0.6899 - val_loss: 0.6895\n",
      "Epoch 12/1000\n",
      "59/59 [==============================] - 0s 1ms/step - loss: 0.6894 - val_loss: 0.6890\n",
      "Epoch 13/1000\n",
      "59/59 [==============================] - 0s 729us/step - loss: 0.6889 - val_loss: 0.6885\n",
      "Epoch 14/1000\n",
      "59/59 [==============================] - 0s 763us/step - loss: 0.6884 - val_loss: 0.6879\n",
      "Epoch 15/1000\n",
      "59/59 [==============================] - 0s 966us/step - loss: 0.6878 - val_loss: 0.6872\n",
      "Epoch 16/1000\n",
      "59/59 [==============================] - 0s 814us/step - loss: 0.6871 - val_loss: 0.6865\n",
      "Epoch 17/1000\n",
      "59/59 [==============================] - 0s 932us/step - loss: 0.6863 - val_loss: 0.6857\n",
      "Epoch 18/1000\n",
      "59/59 [==============================] - 0s 864us/step - loss: 0.6855 - val_loss: 0.6847\n",
      "Epoch 19/1000\n",
      "59/59 [==============================] - 0s 797us/step - loss: 0.6845 - val_loss: 0.6837\n",
      "Epoch 20/1000\n",
      "59/59 [==============================] - 0s 831us/step - loss: 0.6835 - val_loss: 0.6826\n",
      "Epoch 21/1000\n",
      "59/59 [==============================] - 0s 932us/step - loss: 0.6823 - val_loss: 0.6814\n",
      "Epoch 22/1000\n",
      "59/59 [==============================] - 0s 831us/step - loss: 0.6811 - val_loss: 0.6800\n",
      "Epoch 23/1000\n",
      "59/59 [==============================] - 0s 932us/step - loss: 0.6797 - val_loss: 0.6785\n",
      "Epoch 24/1000\n",
      "59/59 [==============================] - 0s 780us/step - loss: 0.6782 - val_loss: 0.6769\n",
      "Epoch 25/1000\n",
      "59/59 [==============================] - 0s 932us/step - loss: 0.6765 - val_loss: 0.6751\n",
      "Epoch 26/1000\n",
      "59/59 [==============================] - 0s 831us/step - loss: 0.6747 - val_loss: 0.6733\n",
      "Epoch 27/1000\n",
      "59/59 [==============================] - 0s 729us/step - loss: 0.6729 - val_loss: 0.6713\n",
      "Epoch 28/1000\n",
      "59/59 [==============================] - 0s 966us/step - loss: 0.6708 - val_loss: 0.6692\n",
      "Epoch 29/1000\n",
      "59/59 [==============================] - 0s 712us/step - loss: 0.6687 - val_loss: 0.6670\n",
      "Epoch 30/1000\n",
      "59/59 [==============================] - 0s 763us/step - loss: 0.6665 - val_loss: 0.6647\n",
      "Epoch 31/1000\n",
      "59/59 [==============================] - 0s 746us/step - loss: 0.6642 - val_loss: 0.6624\n",
      "Epoch 32/1000\n",
      "59/59 [==============================] - 0s 864us/step - loss: 0.6618 - val_loss: 0.6600\n",
      "Epoch 33/1000\n",
      "59/59 [==============================] - 0s 763us/step - loss: 0.6594 - val_loss: 0.6576\n",
      "Epoch 34/1000\n",
      "59/59 [==============================] - 0s 831us/step - loss: 0.6571 - val_loss: 0.6552\n",
      "Epoch 35/1000\n",
      "59/59 [==============================] - 0s 746us/step - loss: 0.6547 - val_loss: 0.6528\n",
      "Epoch 36/1000\n",
      "59/59 [==============================] - 0s 848us/step - loss: 0.6523 - val_loss: 0.6506\n",
      "Epoch 37/1000\n",
      "59/59 [==============================] - 0s 746us/step - loss: 0.6501 - val_loss: 0.6484\n",
      "Epoch 38/1000\n",
      "59/59 [==============================] - 0s 915us/step - loss: 0.6481 - val_loss: 0.6464\n",
      "Epoch 39/1000\n",
      "59/59 [==============================] - 0s 966us/step - loss: 0.6460 - val_loss: 0.6444\n",
      "Epoch 40/1000\n",
      "59/59 [==============================] - 0s 695us/step - loss: 0.6441 - val_loss: 0.6426\n",
      "Epoch 41/1000\n",
      "59/59 [==============================] - 0s 831us/step - loss: 0.6422 - val_loss: 0.6409\n",
      "Epoch 42/1000\n",
      "59/59 [==============================] - 0s 814us/step - loss: 0.6406 - val_loss: 0.6393\n",
      "Epoch 43/1000\n",
      "59/59 [==============================] - 0s 848us/step - loss: 0.6390 - val_loss: 0.6379\n",
      "Epoch 44/1000\n",
      "59/59 [==============================] - 0s 966us/step - loss: 0.6376 - val_loss: 0.6366\n",
      "Epoch 45/1000\n",
      "59/59 [==============================] - 0s 797us/step - loss: 0.6364 - val_loss: 0.6354\n",
      "Epoch 46/1000\n",
      "59/59 [==============================] - 0s 1ms/step - loss: 0.6352 - val_loss: 0.6343\n",
      "Epoch 47/1000\n",
      "59/59 [==============================] - 0s 881us/step - loss: 0.6343 - val_loss: 0.6334\n",
      "Epoch 48/1000\n",
      "59/59 [==============================] - 0s 848us/step - loss: 0.6332 - val_loss: 0.6325\n",
      "Epoch 49/1000\n",
      "59/59 [==============================] - 0s 627us/step - loss: 0.6323 - val_loss: 0.6317\n",
      "Epoch 50/1000\n",
      "59/59 [==============================] - 0s 780us/step - loss: 0.6316 - val_loss: 0.6310\n",
      "Epoch 51/1000\n",
      "59/59 [==============================] - 0s 780us/step - loss: 0.6309 - val_loss: 0.6303\n",
      "Epoch 52/1000\n",
      "59/59 [==============================] - 0s 881us/step - loss: 0.6302 - val_loss: 0.6297\n",
      "Epoch 53/1000\n",
      "59/59 [==============================] - 0s 729us/step - loss: 0.6296 - val_loss: 0.6292\n",
      "Epoch 54/1000\n",
      "59/59 [==============================] - 0s 949us/step - loss: 0.6291 - val_loss: 0.6286\n",
      "Epoch 55/1000\n",
      "59/59 [==============================] - 0s 661us/step - loss: 0.6286 - val_loss: 0.6281\n",
      "Epoch 56/1000\n",
      "59/59 [==============================] - 0s 983us/step - loss: 0.6281 - val_loss: 0.6277\n",
      "Epoch 57/1000\n",
      "59/59 [==============================] - 0s 712us/step - loss: 0.6277 - val_loss: 0.6273\n",
      "Epoch 58/1000\n",
      "59/59 [==============================] - 0s 831us/step - loss: 0.6272 - val_loss: 0.6268\n",
      "Epoch 59/1000\n",
      "59/59 [==============================] - 0s 814us/step - loss: 0.6268 - val_loss: 0.6264\n",
      "Epoch 60/1000\n",
      "59/59 [==============================] - 0s 746us/step - loss: 0.6264 - val_loss: 0.6261\n",
      "Epoch 61/1000\n",
      "59/59 [==============================] - 0s 898us/step - loss: 0.6260 - val_loss: 0.6257\n",
      "Epoch 62/1000\n",
      "59/59 [==============================] - 0s 966us/step - loss: 0.6257 - val_loss: 0.6253\n",
      "Epoch 63/1000\n",
      "59/59 [==============================] - 0s 949us/step - loss: 0.6253 - val_loss: 0.6250\n",
      "Epoch 64/1000\n",
      "59/59 [==============================] - 0s 644us/step - loss: 0.6249 - val_loss: 0.6246\n",
      "Epoch 65/1000\n",
      "59/59 [==============================] - 0s 864us/step - loss: 0.6246 - val_loss: 0.6243\n",
      "Epoch 66/1000\n",
      "59/59 [==============================] - 0s 831us/step - loss: 0.6242 - val_loss: 0.6239\n",
      "Epoch 67/1000\n",
      "59/59 [==============================] - 0s 864us/step - loss: 0.6239 - val_loss: 0.6236\n",
      "Epoch 68/1000\n",
      "59/59 [==============================] - 0s 949us/step - loss: 0.6236 - val_loss: 0.6232\n",
      "Epoch 69/1000\n",
      "59/59 [==============================] - 0s 746us/step - loss: 0.6231 - val_loss: 0.6228\n",
      "Epoch 70/1000\n",
      "59/59 [==============================] - 0s 712us/step - loss: 0.6228 - val_loss: 0.6225\n",
      "Epoch 71/1000\n",
      "59/59 [==============================] - 0s 814us/step - loss: 0.6224 - val_loss: 0.6221\n",
      "Epoch 72/1000\n",
      "59/59 [==============================] - 0s 797us/step - loss: 0.6221 - val_loss: 0.6217\n",
      "Epoch 73/1000\n",
      "59/59 [==============================] - 0s 712us/step - loss: 0.6217 - val_loss: 0.6214\n",
      "Epoch 74/1000\n",
      "59/59 [==============================] - 0s 814us/step - loss: 0.6213 - val_loss: 0.6210\n",
      "Epoch 75/1000\n",
      "59/59 [==============================] - 0s 661us/step - loss: 0.6210 - val_loss: 0.6206\n",
      "Epoch 76/1000\n",
      "59/59 [==============================] - 0s 1ms/step - loss: 0.6206 - val_loss: 0.6202\n",
      "Epoch 77/1000\n",
      "59/59 [==============================] - 0s 661us/step - loss: 0.6202 - val_loss: 0.6198\n",
      "Epoch 78/1000\n",
      "59/59 [==============================] - 0s 1ms/step - loss: 0.6198 - val_loss: 0.6194\n",
      "Epoch 79/1000\n",
      "59/59 [==============================] - 0s 661us/step - loss: 0.6194 - val_loss: 0.6190\n",
      "Epoch 80/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59/59 [==============================] - 0s 678us/step - loss: 0.6191 - val_loss: 0.6186\n",
      "Epoch 81/1000\n",
      "59/59 [==============================] - 0s 814us/step - loss: 0.6186 - val_loss: 0.6182\n",
      "Epoch 82/1000\n",
      "59/59 [==============================] - 0s 1ms/step - loss: 0.6182 - val_loss: 0.6178\n",
      "Epoch 83/1000\n",
      "59/59 [==============================] - 0s 729us/step - loss: 0.6177 - val_loss: 0.6174\n",
      "Epoch 84/1000\n",
      "59/59 [==============================] - 0s 1ms/step - loss: 0.6173 - val_loss: 0.6169\n",
      "Epoch 85/1000\n",
      "59/59 [==============================] - 0s 1ms/step - loss: 0.6169 - val_loss: 0.6165\n",
      "Epoch 86/1000\n",
      "59/59 [==============================] - 0s 1ms/step - loss: 0.6165 - val_loss: 0.6161\n",
      "Epoch 87/1000\n",
      "59/59 [==============================] - 0s 881us/step - loss: 0.6160 - val_loss: 0.6156\n",
      "Epoch 88/1000\n",
      "59/59 [==============================] - 0s 949us/step - loss: 0.6155 - val_loss: 0.6151\n",
      "Epoch 89/1000\n",
      "59/59 [==============================] - 0s 915us/step - loss: 0.6151 - val_loss: 0.6147\n",
      "Epoch 90/1000\n",
      "59/59 [==============================] - 0s 881us/step - loss: 0.6146 - val_loss: 0.6142\n",
      "Epoch 91/1000\n",
      "59/59 [==============================] - 0s 949us/step - loss: 0.6141 - val_loss: 0.6137\n",
      "Epoch 92/1000\n",
      "59/59 [==============================] - 0s 864us/step - loss: 0.6137 - val_loss: 0.6133\n",
      "Epoch 93/1000\n",
      "59/59 [==============================] - 0s 898us/step - loss: 0.6132 - val_loss: 0.6128\n",
      "Epoch 94/1000\n",
      "59/59 [==============================] - 0s 797us/step - loss: 0.6128 - val_loss: 0.6123\n",
      "Epoch 95/1000\n",
      "59/59 [==============================] - 0s 780us/step - loss: 0.6122 - val_loss: 0.6118\n",
      "Epoch 96/1000\n",
      "59/59 [==============================] - 0s 661us/step - loss: 0.6118 - val_loss: 0.6113\n",
      "Epoch 97/1000\n",
      "59/59 [==============================] - 0s 746us/step - loss: 0.6112 - val_loss: 0.6108\n",
      "Epoch 98/1000\n",
      "59/59 [==============================] - 0s 1ms/step - loss: 0.6108 - val_loss: 0.6103\n",
      "Epoch 99/1000\n",
      "59/59 [==============================] - 0s 797us/step - loss: 0.6103 - val_loss: 0.6098\n",
      "Epoch 100/1000\n",
      "59/59 [==============================] - 0s 848us/step - loss: 0.6098 - val_loss: 0.6093\n",
      "Epoch 101/1000\n",
      "59/59 [==============================] - 0s 1ms/step - loss: 0.6093 - val_loss: 0.6089\n",
      "Epoch 102/1000\n",
      "59/59 [==============================] - 0s 864us/step - loss: 0.6088 - val_loss: 0.6084\n",
      "Epoch 103/1000\n",
      "59/59 [==============================] - 0s 627us/step - loss: 0.6083 - val_loss: 0.6079\n",
      "Epoch 104/1000\n",
      "59/59 [==============================] - 0s 949us/step - loss: 0.6079 - val_loss: 0.6074\n",
      "Epoch 105/1000\n",
      "59/59 [==============================] - 0s 763us/step - loss: 0.6075 - val_loss: 0.6069\n",
      "Epoch 106/1000\n",
      "59/59 [==============================] - 0s 746us/step - loss: 0.6069 - val_loss: 0.6065\n",
      "Epoch 107/1000\n",
      "59/59 [==============================] - 0s 746us/step - loss: 0.6064 - val_loss: 0.6060\n",
      "Epoch 108/1000\n",
      "59/59 [==============================] - 0s 644us/step - loss: 0.6059 - val_loss: 0.6055\n",
      "Epoch 109/1000\n",
      "59/59 [==============================] - 0s 729us/step - loss: 0.6054 - val_loss: 0.6051\n",
      "Epoch 110/1000\n",
      "59/59 [==============================] - 0s 644us/step - loss: 0.6050 - val_loss: 0.6046\n",
      "Epoch 111/1000\n",
      "59/59 [==============================] - 0s 746us/step - loss: 0.6046 - val_loss: 0.6042\n",
      "Epoch 112/1000\n",
      "59/59 [==============================] - 0s 746us/step - loss: 0.6041 - val_loss: 0.6037\n",
      "Epoch 113/1000\n",
      "59/59 [==============================] - 0s 644us/step - loss: 0.6036 - val_loss: 0.6033\n",
      "Epoch 114/1000\n",
      "59/59 [==============================] - 0s 729us/step - loss: 0.6032 - val_loss: 0.6028\n",
      "Epoch 115/1000\n",
      "59/59 [==============================] - 0s 746us/step - loss: 0.6028 - val_loss: 0.6024\n",
      "Epoch 116/1000\n",
      "59/59 [==============================] - 0s 729us/step - loss: 0.6023 - val_loss: 0.6020\n",
      "Epoch 117/1000\n",
      "59/59 [==============================] - 0s 814us/step - loss: 0.6019 - val_loss: 0.6016\n",
      "Epoch 118/1000\n",
      "59/59 [==============================] - 0s 661us/step - loss: 0.6015 - val_loss: 0.6012\n",
      "Epoch 119/1000\n",
      "59/59 [==============================] - 0s 780us/step - loss: 0.6011 - val_loss: 0.6008\n",
      "Epoch 120/1000\n",
      "59/59 [==============================] - 0s 763us/step - loss: 0.6007 - val_loss: 0.6004\n",
      "Epoch 121/1000\n",
      "59/59 [==============================] - 0s 1ms/step - loss: 0.6004 - val_loss: 0.6000\n",
      "Epoch 122/1000\n",
      "59/59 [==============================] - 0s 932us/step - loss: 0.5999 - val_loss: 0.5996\n",
      "Epoch 123/1000\n",
      "59/59 [==============================] - 0s 797us/step - loss: 0.5996 - val_loss: 0.5992\n",
      "Epoch 124/1000\n",
      "59/59 [==============================] - 0s 1ms/step - loss: 0.5991 - val_loss: 0.5988\n",
      "Epoch 125/1000\n",
      "59/59 [==============================] - 0s 814us/step - loss: 0.5988 - val_loss: 0.5985\n",
      "Epoch 126/1000\n",
      "59/59 [==============================] - 0s 678us/step - loss: 0.5985 - val_loss: 0.5981\n",
      "Epoch 127/1000\n",
      "59/59 [==============================] - 0s 763us/step - loss: 0.5981 - val_loss: 0.5978\n",
      "Epoch 128/1000\n",
      "59/59 [==============================] - 0s 678us/step - loss: 0.5978 - val_loss: 0.5975\n",
      "Epoch 129/1000\n",
      "59/59 [==============================] - 0s 746us/step - loss: 0.5974 - val_loss: 0.5971\n",
      "Epoch 130/1000\n",
      "59/59 [==============================] - 0s 610us/step - loss: 0.5971 - val_loss: 0.5968\n",
      "Epoch 131/1000\n",
      "59/59 [==============================] - 0s 780us/step - loss: 0.5968 - val_loss: 0.5965\n",
      "Epoch 132/1000\n",
      "59/59 [==============================] - 0s 780us/step - loss: 0.5964 - val_loss: 0.5962\n",
      "Epoch 133/1000\n",
      "59/59 [==============================] - 0s 678us/step - loss: 0.5962 - val_loss: 0.5959\n",
      "Epoch 134/1000\n",
      "59/59 [==============================] - 0s 746us/step - loss: 0.5958 - val_loss: 0.5956\n",
      "Epoch 135/1000\n",
      "59/59 [==============================] - 0s 881us/step - loss: 0.5956 - val_loss: 0.5953\n",
      "Epoch 136/1000\n",
      "59/59 [==============================] - 0s 797us/step - loss: 0.5952 - val_loss: 0.5950\n",
      "Epoch 137/1000\n",
      "59/59 [==============================] - 0s 678us/step - loss: 0.5950 - val_loss: 0.5947\n",
      "Epoch 138/1000\n",
      "59/59 [==============================] - 0s 848us/step - loss: 0.5947 - val_loss: 0.5945\n",
      "Epoch 139/1000\n",
      "59/59 [==============================] - 0s 661us/step - loss: 0.5944 - val_loss: 0.5942\n",
      "Epoch 140/1000\n",
      "59/59 [==============================] - 0s 814us/step - loss: 0.5942 - val_loss: 0.5939\n",
      "Epoch 141/1000\n",
      "59/59 [==============================] - 0s 746us/step - loss: 0.5939 - val_loss: 0.5937\n",
      "Epoch 142/1000\n",
      "59/59 [==============================] - 0s 1ms/step - loss: 0.5936 - val_loss: 0.5934\n",
      "Epoch 143/1000\n",
      "59/59 [==============================] - 0s 1ms/step - loss: 0.5934 - val_loss: 0.5932\n",
      "Epoch 144/1000\n",
      "59/59 [==============================] - 0s 1ms/step - loss: 0.5932 - val_loss: 0.5930\n",
      "Epoch 145/1000\n",
      "59/59 [==============================] - 0s 661us/step - loss: 0.5929 - val_loss: 0.5927\n",
      "Epoch 146/1000\n",
      "59/59 [==============================] - 0s 814us/step - loss: 0.5927 - val_loss: 0.5925\n",
      "Epoch 147/1000\n",
      "59/59 [==============================] - 0s 848us/step - loss: 0.5925 - val_loss: 0.5923\n",
      "Epoch 148/1000\n",
      "59/59 [==============================] - 0s 881us/step - loss: 0.5923 - val_loss: 0.5920\n",
      "Epoch 149/1000\n",
      "59/59 [==============================] - 0s 864us/step - loss: 0.5922 - val_loss: 0.5918\n",
      "Epoch 150/1000\n",
      "59/59 [==============================] - 0s 915us/step - loss: 0.5918 - val_loss: 0.5916\n",
      "Epoch 151/1000\n",
      "59/59 [==============================] - 0s 763us/step - loss: 0.5916 - val_loss: 0.5914\n",
      "Epoch 152/1000\n",
      "59/59 [==============================] - 0s 932us/step - loss: 0.5914 - val_loss: 0.5912\n",
      "Epoch 153/1000\n",
      "59/59 [==============================] - 0s 881us/step - loss: 0.5912 - val_loss: 0.5910\n",
      "Epoch 154/1000\n",
      "59/59 [==============================] - 0s 746us/step - loss: 0.5910 - val_loss: 0.5908\n",
      "Epoch 155/1000\n",
      "59/59 [==============================] - 0s 644us/step - loss: 0.5908 - val_loss: 0.5906\n",
      "Epoch 156/1000\n",
      "59/59 [==============================] - 0s 797us/step - loss: 0.5906 - val_loss: 0.5904\n",
      "Epoch 157/1000\n",
      "59/59 [==============================] - 0s 780us/step - loss: 0.5904 - val_loss: 0.5902\n",
      "Epoch 158/1000\n",
      "59/59 [==============================] - 0s 678us/step - loss: 0.5902 - val_loss: 0.5900\n",
      "Epoch 159/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59/59 [==============================] - 0s 678us/step - loss: 0.5901 - val_loss: 0.5898\n",
      "Epoch 160/1000\n",
      "59/59 [==============================] - 0s 797us/step - loss: 0.5898 - val_loss: 0.5896\n",
      "Epoch 161/1000\n",
      "59/59 [==============================] - 0s 712us/step - loss: 0.5896 - val_loss: 0.5895\n",
      "Epoch 162/1000\n",
      "59/59 [==============================] - 0s 644us/step - loss: 0.5894 - val_loss: 0.5893\n",
      "Epoch 163/1000\n",
      "59/59 [==============================] - 0s 814us/step - loss: 0.5893 - val_loss: 0.5891\n",
      "Epoch 164/1000\n",
      "59/59 [==============================] - 0s 1ms/step - loss: 0.5891 - val_loss: 0.5889\n",
      "Epoch 165/1000\n",
      "59/59 [==============================] - 0s 797us/step - loss: 0.5889 - val_loss: 0.5887\n",
      "Epoch 166/1000\n",
      "59/59 [==============================] - 0s 814us/step - loss: 0.5887 - val_loss: 0.5886\n",
      "Epoch 167/1000\n",
      "59/59 [==============================] - 0s 898us/step - loss: 0.5886 - val_loss: 0.5884\n",
      "Epoch 168/1000\n",
      "59/59 [==============================] - 0s 898us/step - loss: 0.5884 - val_loss: 0.5882\n",
      "Epoch 169/1000\n",
      "59/59 [==============================] - 0s 898us/step - loss: 0.5882 - val_loss: 0.5881\n",
      "Epoch 170/1000\n",
      "59/59 [==============================] - 0s 915us/step - loss: 0.5881 - val_loss: 0.5879\n",
      "Epoch 171/1000\n",
      "59/59 [==============================] - 0s 864us/step - loss: 0.5879 - val_loss: 0.5877\n",
      "Epoch 172/1000\n",
      "59/59 [==============================] - 0s 898us/step - loss: 0.5878 - val_loss: 0.5876\n",
      "Epoch 173/1000\n",
      "59/59 [==============================] - 0s 898us/step - loss: 0.5876 - val_loss: 0.5874\n",
      "Epoch 174/1000\n",
      "59/59 [==============================] - 0s 881us/step - loss: 0.5874 - val_loss: 0.5872\n",
      "Epoch 175/1000\n",
      "59/59 [==============================] - 0s 661us/step - loss: 0.5872 - val_loss: 0.5871\n",
      "Epoch 176/1000\n",
      "59/59 [==============================] - 0s 898us/step - loss: 0.5871 - val_loss: 0.5869\n",
      "Epoch 177/1000\n",
      "59/59 [==============================] - 0s 881us/step - loss: 0.5869 - val_loss: 0.5868\n",
      "Epoch 178/1000\n",
      "59/59 [==============================] - 0s 831us/step - loss: 0.5868 - val_loss: 0.5866\n",
      "Epoch 179/1000\n",
      "59/59 [==============================] - 0s 881us/step - loss: 0.5866 - val_loss: 0.5864\n",
      "Epoch 180/1000\n",
      "59/59 [==============================] - 0s 814us/step - loss: 0.5865 - val_loss: 0.5863\n",
      "Epoch 181/1000\n",
      "59/59 [==============================] - 0s 848us/step - loss: 0.5863 - val_loss: 0.5861\n",
      "Epoch 182/1000\n",
      "59/59 [==============================] - 0s 746us/step - loss: 0.5861 - val_loss: 0.5860\n",
      "Epoch 183/1000\n",
      "59/59 [==============================] - 0s 729us/step - loss: 0.5860 - val_loss: 0.5858\n",
      "Epoch 184/1000\n",
      "59/59 [==============================] - 0s 864us/step - loss: 0.5858 - val_loss: 0.5857\n",
      "Epoch 185/1000\n",
      "59/59 [==============================] - 0s 746us/step - loss: 0.5857 - val_loss: 0.5855\n",
      "Epoch 186/1000\n",
      "59/59 [==============================] - 0s 1ms/step - loss: 0.5856 - val_loss: 0.5854\n",
      "Epoch 187/1000\n",
      "59/59 [==============================] - 0s 949us/step - loss: 0.5854 - val_loss: 0.5852\n",
      "Epoch 188/1000\n",
      "59/59 [==============================] - 0s 848us/step - loss: 0.5852 - val_loss: 0.5851\n",
      "Epoch 189/1000\n",
      "59/59 [==============================] - 0s 1ms/step - loss: 0.5851 - val_loss: 0.5849\n",
      "Epoch 190/1000\n",
      "59/59 [==============================] - 0s 831us/step - loss: 0.5849 - val_loss: 0.5848\n",
      "Epoch 191/1000\n",
      "59/59 [==============================] - 0s 1ms/step - loss: 0.5848 - val_loss: 0.5846\n",
      "Epoch 192/1000\n",
      "59/59 [==============================] - 0s 661us/step - loss: 0.5846 - val_loss: 0.5845\n",
      "Epoch 193/1000\n",
      "59/59 [==============================] - 0s 1ms/step - loss: 0.5845 - val_loss: 0.5843\n",
      "Epoch 194/1000\n",
      "59/59 [==============================] - 0s 1ms/step - loss: 0.5843 - val_loss: 0.5842\n",
      "Epoch 195/1000\n",
      "59/59 [==============================] - 0s 881us/step - loss: 0.5841 - val_loss: 0.5840\n",
      "Epoch 196/1000\n",
      "59/59 [==============================] - 0s 814us/step - loss: 0.5840 - val_loss: 0.5839\n",
      "Epoch 197/1000\n",
      "59/59 [==============================] - 0s 712us/step - loss: 0.5839 - val_loss: 0.5837\n",
      "Epoch 198/1000\n",
      "59/59 [==============================] - 0s 746us/step - loss: 0.5837 - val_loss: 0.5836\n",
      "Epoch 199/1000\n",
      "59/59 [==============================] - 0s 644us/step - loss: 0.5836 - val_loss: 0.5834\n",
      "Epoch 200/1000\n",
      "59/59 [==============================] - 0s 881us/step - loss: 0.5834 - val_loss: 0.5833\n",
      "Epoch 201/1000\n",
      "59/59 [==============================] - 0s 983us/step - loss: 0.5832 - val_loss: 0.5831\n",
      "Epoch 202/1000\n",
      "59/59 [==============================] - 0s 915us/step - loss: 0.5831 - val_loss: 0.5830\n",
      "Epoch 203/1000\n",
      "59/59 [==============================] - 0s 932us/step - loss: 0.5830 - val_loss: 0.5828\n",
      "Epoch 204/1000\n",
      "59/59 [==============================] - 0s 797us/step - loss: 0.5828 - val_loss: 0.5827\n",
      "Epoch 205/1000\n",
      "59/59 [==============================] - 0s 712us/step - loss: 0.5828 - val_loss: 0.5825\n",
      "Epoch 206/1000\n",
      "59/59 [==============================] - 0s 644us/step - loss: 0.5826 - val_loss: 0.5824\n",
      "Epoch 207/1000\n",
      "59/59 [==============================] - 0s 915us/step - loss: 0.5824 - val_loss: 0.5822\n",
      "Epoch 208/1000\n",
      "59/59 [==============================] - 0s 864us/step - loss: 0.5822 - val_loss: 0.5821\n",
      "Epoch 209/1000\n",
      "59/59 [==============================] - 0s 831us/step - loss: 0.5821 - val_loss: 0.5819\n",
      "Epoch 210/1000\n",
      "59/59 [==============================] - 0s 678us/step - loss: 0.5820 - val_loss: 0.5818\n",
      "Epoch 211/1000\n",
      "59/59 [==============================] - 0s 898us/step - loss: 0.5818 - val_loss: 0.5816\n",
      "Epoch 212/1000\n",
      "59/59 [==============================] - 0s 712us/step - loss: 0.5816 - val_loss: 0.5815\n",
      "Epoch 213/1000\n",
      "59/59 [==============================] - 0s 797us/step - loss: 0.5815 - val_loss: 0.5813\n",
      "Epoch 214/1000\n",
      "59/59 [==============================] - 0s 831us/step - loss: 0.5813 - val_loss: 0.5812\n",
      "Epoch 215/1000\n",
      "59/59 [==============================] - 0s 712us/step - loss: 0.5811 - val_loss: 0.5810\n",
      "Epoch 216/1000\n",
      "59/59 [==============================] - 0s 848us/step - loss: 0.5810 - val_loss: 0.5809\n",
      "Epoch 217/1000\n",
      "59/59 [==============================] - 0s 983us/step - loss: 0.5809 - val_loss: 0.5807\n",
      "Epoch 218/1000\n",
      "59/59 [==============================] - 0s 678us/step - loss: 0.5807 - val_loss: 0.5806\n",
      "Epoch 219/1000\n",
      "59/59 [==============================] - 0s 864us/step - loss: 0.5806 - val_loss: 0.5804\n",
      "Epoch 220/1000\n",
      "59/59 [==============================] - 0s 729us/step - loss: 0.5804 - val_loss: 0.5803\n",
      "Epoch 221/1000\n",
      "59/59 [==============================] - 0s 780us/step - loss: 0.5803 - val_loss: 0.5801\n",
      "Epoch 222/1000\n",
      "59/59 [==============================] - 0s 729us/step - loss: 0.5801 - val_loss: 0.5800\n",
      "Epoch 223/1000\n",
      "59/59 [==============================] - 0s 881us/step - loss: 0.5800 - val_loss: 0.5798\n",
      "Epoch 224/1000\n",
      "59/59 [==============================] - 0s 848us/step - loss: 0.5798 - val_loss: 0.5797\n",
      "Epoch 225/1000\n",
      "59/59 [==============================] - 0s 729us/step - loss: 0.5797 - val_loss: 0.5796\n",
      "Epoch 226/1000\n",
      "59/59 [==============================] - 0s 695us/step - loss: 0.5795 - val_loss: 0.5794\n",
      "Epoch 227/1000\n",
      "59/59 [==============================] - 0s 814us/step - loss: 0.5794 - val_loss: 0.5793\n",
      "Epoch 228/1000\n",
      "59/59 [==============================] - 0s 678us/step - loss: 0.5792 - val_loss: 0.5791\n",
      "Epoch 229/1000\n",
      "59/59 [==============================] - 0s 949us/step - loss: 0.5792 - val_loss: 0.5790\n",
      "Epoch 230/1000\n",
      "59/59 [==============================] - 0s 661us/step - loss: 0.5790 - val_loss: 0.5788\n",
      "Epoch 231/1000\n",
      "59/59 [==============================] - 0s 780us/step - loss: 0.5788 - val_loss: 0.5787\n",
      "Epoch 232/1000\n",
      "59/59 [==============================] - 0s 848us/step - loss: 0.5787 - val_loss: 0.5785\n",
      "Epoch 233/1000\n",
      "59/59 [==============================] - 0s 763us/step - loss: 0.5785 - val_loss: 0.5784\n",
      "Epoch 234/1000\n",
      "59/59 [==============================] - 0s 848us/step - loss: 0.5784 - val_loss: 0.5782\n",
      "Epoch 235/1000\n",
      "59/59 [==============================] - 0s 695us/step - loss: 0.5784 - val_loss: 0.5781\n",
      "Epoch 236/1000\n",
      "59/59 [==============================] - 0s 898us/step - loss: 0.5781 - val_loss: 0.5780\n",
      "Epoch 237/1000\n",
      "59/59 [==============================] - 0s 898us/step - loss: 0.5780 - val_loss: 0.5778\n",
      "Epoch 238/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59/59 [==============================] - 0s 932us/step - loss: 0.5778 - val_loss: 0.5777\n",
      "Epoch 239/1000\n",
      "59/59 [==============================] - 0s 1ms/step - loss: 0.5777 - val_loss: 0.5775\n",
      "Epoch 240/1000\n",
      "59/59 [==============================] - 0s 881us/step - loss: 0.5775 - val_loss: 0.5774\n",
      "Epoch 241/1000\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 0.5774 - val_loss: 0.5773\n",
      "Epoch 242/1000\n",
      "59/59 [==============================] - 0s 1ms/step - loss: 0.5772 - val_loss: 0.5771\n",
      "Epoch 243/1000\n",
      "59/59 [==============================] - 0s 1ms/step - loss: 0.5771 - val_loss: 0.5770\n",
      "Epoch 244/1000\n",
      "59/59 [==============================] - 0s 1ms/step - loss: 0.5770 - val_loss: 0.5768\n",
      "Epoch 245/1000\n",
      "59/59 [==============================] - ETA: 0s - loss: 0.572 - 0s 1ms/step - loss: 0.5768 - val_loss: 0.5767\n",
      "Epoch 246/1000\n",
      "59/59 [==============================] - 0s 932us/step - loss: 0.5767 - val_loss: 0.5766\n",
      "Epoch 247/1000\n",
      "59/59 [==============================] - 0s 1ms/step - loss: 0.5765 - val_loss: 0.5764\n",
      "Epoch 248/1000\n",
      "59/59 [==============================] - 0s 1ms/step - loss: 0.5764 - val_loss: 0.5763\n",
      "Epoch 249/1000\n",
      "59/59 [==============================] - 0s 1ms/step - loss: 0.5763 - val_loss: 0.5762\n",
      "Epoch 250/1000\n",
      "59/59 [==============================] - 0s 1ms/step - loss: 0.5761 - val_loss: 0.5760\n",
      "Epoch 251/1000\n",
      "59/59 [==============================] - 0s 932us/step - loss: 0.5760 - val_loss: 0.5759\n",
      "Epoch 252/1000\n",
      "59/59 [==============================] - 0s 966us/step - loss: 0.5759 - val_loss: 0.5757\n",
      "Epoch 253/1000\n",
      "59/59 [==============================] - 0s 1ms/step - loss: 0.5758 - val_loss: 0.5756\n",
      "Epoch 254/1000\n",
      "59/59 [==============================] - 0s 1ms/step - loss: 0.5756 - val_loss: 0.5755\n",
      "Epoch 255/1000\n",
      "59/59 [==============================] - 0s 932us/step - loss: 0.5755 - val_loss: 0.5753\n",
      "Epoch 256/1000\n",
      "59/59 [==============================] - 0s 966us/step - loss: 0.5753 - val_loss: 0.5752\n",
      "Epoch 257/1000\n",
      "59/59 [==============================] - 0s 1ms/step - loss: 0.5752 - val_loss: 0.5751\n",
      "Epoch 258/1000\n",
      "59/59 [==============================] - 0s 949us/step - loss: 0.5751 - val_loss: 0.5749\n",
      "Epoch 259/1000\n",
      "59/59 [==============================] - 0s 1ms/step - loss: 0.5749 - val_loss: 0.5748\n",
      "Epoch 260/1000\n",
      "59/59 [==============================] - 0s 780us/step - loss: 0.5748 - val_loss: 0.5747\n",
      "Epoch 261/1000\n",
      "59/59 [==============================] - 0s 898us/step - loss: 0.5747 - val_loss: 0.5745\n",
      "Epoch 262/1000\n",
      "59/59 [==============================] - 0s 864us/step - loss: 0.5746 - val_loss: 0.5744\n",
      "Epoch 263/1000\n",
      "59/59 [==============================] - 0s 966us/step - loss: 0.5744 - val_loss: 0.5743\n",
      "Epoch 264/1000\n",
      "59/59 [==============================] - 0s 1ms/step - loss: 0.5743 - val_loss: 0.5741\n",
      "Epoch 265/1000\n",
      "59/59 [==============================] - 0s 1ms/step - loss: 0.5742 - val_loss: 0.5740\n",
      "Epoch 266/1000\n",
      "59/59 [==============================] - 0s 1ms/step - loss: 0.5740 - val_loss: 0.5739\n",
      "Epoch 267/1000\n",
      "59/59 [==============================] - 0s 831us/step - loss: 0.5739 - val_loss: 0.5738\n",
      "Epoch 268/1000\n",
      "59/59 [==============================] - 0s 898us/step - loss: 0.5738 - val_loss: 0.5736\n",
      "Epoch 269/1000\n",
      "59/59 [==============================] - 0s 881us/step - loss: 0.5736 - val_loss: 0.5735\n",
      "Epoch 270/1000\n",
      "59/59 [==============================] - 0s 814us/step - loss: 0.5735 - val_loss: 0.5734\n",
      "Epoch 271/1000\n",
      "59/59 [==============================] - 0s 949us/step - loss: 0.5734 - val_loss: 0.5732\n",
      "Epoch 272/1000\n",
      "59/59 [==============================] - 0s 983us/step - loss: 0.5733 - val_loss: 0.5731\n",
      "Epoch 273/1000\n",
      "59/59 [==============================] - 0s 780us/step - loss: 0.5731 - val_loss: 0.5730\n",
      "Epoch 274/1000\n",
      "59/59 [==============================] - 0s 915us/step - loss: 0.5730 - val_loss: 0.5729\n",
      "Epoch 275/1000\n",
      "59/59 [==============================] - 0s 915us/step - loss: 0.5729 - val_loss: 0.5727\n",
      "Epoch 276/1000\n",
      "59/59 [==============================] - 0s 814us/step - loss: 0.5728 - val_loss: 0.5726\n",
      "Epoch 277/1000\n",
      "59/59 [==============================] - 0s 1ms/step - loss: 0.5726 - val_loss: 0.5725\n",
      "Epoch 278/1000\n",
      "59/59 [==============================] - 0s 848us/step - loss: 0.5725 - val_loss: 0.5724\n",
      "Epoch 279/1000\n",
      "59/59 [==============================] - 0s 932us/step - loss: 0.5724 - val_loss: 0.5722\n",
      "Epoch 280/1000\n",
      "59/59 [==============================] - 0s 797us/step - loss: 0.5723 - val_loss: 0.5721\n",
      "Epoch 281/1000\n",
      "59/59 [==============================] - 0s 814us/step - loss: 0.5721 - val_loss: 0.5720\n",
      "Epoch 282/1000\n",
      "59/59 [==============================] - 0s 898us/step - loss: 0.5720 - val_loss: 0.5719\n",
      "Epoch 283/1000\n",
      "59/59 [==============================] - 0s 814us/step - loss: 0.5719 - val_loss: 0.5718\n",
      "Epoch 284/1000\n",
      "59/59 [==============================] - 0s 814us/step - loss: 0.5718 - val_loss: 0.5716\n",
      "Epoch 285/1000\n",
      "59/59 [==============================] - 0s 1ms/step - loss: 0.5716 - val_loss: 0.5715\n",
      "Epoch 286/1000\n",
      "59/59 [==============================] - 0s 983us/step - loss: 0.5716 - val_loss: 0.5714\n",
      "Epoch 287/1000\n",
      "59/59 [==============================] - 0s 763us/step - loss: 0.5714 - val_loss: 0.5713\n",
      "Epoch 288/1000\n",
      "59/59 [==============================] - 0s 780us/step - loss: 0.5713 - val_loss: 0.5712\n",
      "Epoch 289/1000\n",
      "59/59 [==============================] - 0s 1ms/step - loss: 0.5712 - val_loss: 0.5711\n",
      "Epoch 290/1000\n",
      "59/59 [==============================] - 0s 729us/step - loss: 0.5711 - val_loss: 0.5709\n",
      "Epoch 291/1000\n",
      "59/59 [==============================] - 0s 848us/step - loss: 0.5709 - val_loss: 0.5708\n",
      "Epoch 292/1000\n",
      "59/59 [==============================] - 0s 729us/step - loss: 0.5708 - val_loss: 0.5707\n",
      "Epoch 293/1000\n",
      "59/59 [==============================] - 0s 864us/step - loss: 0.5707 - val_loss: 0.5706\n",
      "Epoch 294/1000\n",
      "59/59 [==============================] - 0s 898us/step - loss: 0.5706 - val_loss: 0.5705\n",
      "Epoch 295/1000\n",
      "59/59 [==============================] - 0s 695us/step - loss: 0.5705 - val_loss: 0.5704\n",
      "Epoch 296/1000\n",
      "59/59 [==============================] - 0s 780us/step - loss: 0.5704 - val_loss: 0.5703\n",
      "Epoch 297/1000\n",
      "59/59 [==============================] - 0s 1ms/step - loss: 0.5702 - val_loss: 0.5701\n",
      "Epoch 298/1000\n",
      "59/59 [==============================] - 0s 712us/step - loss: 0.5701 - val_loss: 0.5700\n",
      "Epoch 299/1000\n",
      "59/59 [==============================] - 0s 746us/step - loss: 0.5700 - val_loss: 0.5699\n",
      "Epoch 300/1000\n",
      "59/59 [==============================] - 0s 949us/step - loss: 0.5699 - val_loss: 0.5698\n",
      "Epoch 301/1000\n",
      "59/59 [==============================] - 0s 831us/step - loss: 0.5699 - val_loss: 0.5697\n",
      "Epoch 302/1000\n",
      "59/59 [==============================] - 0s 915us/step - loss: 0.5698 - val_loss: 0.5696\n",
      "Epoch 303/1000\n",
      "59/59 [==============================] - 0s 797us/step - loss: 0.5696 - val_loss: 0.5695\n",
      "Epoch 304/1000\n",
      "59/59 [==============================] - 0s 898us/step - loss: 0.5695 - val_loss: 0.5694\n",
      "Epoch 305/1000\n",
      "59/59 [==============================] - 0s 814us/step - loss: 0.5694 - val_loss: 0.5693\n",
      "Epoch 306/1000\n",
      "59/59 [==============================] - 0s 661us/step - loss: 0.5693 - val_loss: 0.5692\n",
      "Epoch 307/1000\n",
      "59/59 [==============================] - 0s 932us/step - loss: 0.5691 - val_loss: 0.5691\n",
      "Epoch 308/1000\n",
      "59/59 [==============================] - 0s 881us/step - loss: 0.5691 - val_loss: 0.5689\n",
      "Epoch 309/1000\n",
      "59/59 [==============================] - 0s 763us/step - loss: 0.5689 - val_loss: 0.5688\n",
      "Epoch 310/1000\n",
      "59/59 [==============================] - 0s 966us/step - loss: 0.5688 - val_loss: 0.5687\n",
      "Epoch 311/1000\n",
      "59/59 [==============================] - 0s 814us/step - loss: 0.5687 - val_loss: 0.5686\n",
      "Epoch 312/1000\n",
      "59/59 [==============================] - 0s 712us/step - loss: 0.5686 - val_loss: 0.5685\n",
      "Epoch 313/1000\n",
      "59/59 [==============================] - 0s 814us/step - loss: 0.5685 - val_loss: 0.5684\n",
      "Epoch 314/1000\n",
      "59/59 [==============================] - 0s 729us/step - loss: 0.5684 - val_loss: 0.5683\n",
      "Epoch 315/1000\n",
      "59/59 [==============================] - 0s 831us/step - loss: 0.5683 - val_loss: 0.5682\n",
      "Epoch 316/1000\n",
      "59/59 [==============================] - 0s 814us/step - loss: 0.5682 - val_loss: 0.5681\n",
      "Epoch 317/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59/59 [==============================] - 0s 966us/step - loss: 0.5681 - val_loss: 0.5680\n",
      "Epoch 318/1000\n",
      "59/59 [==============================] - 0s 712us/step - loss: 0.5680 - val_loss: 0.5679\n",
      "Epoch 319/1000\n",
      "59/59 [==============================] - 0s 1ms/step - loss: 0.5679 - val_loss: 0.5678\n",
      "Epoch 320/1000\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 0.5678 - val_loss: 0.5677\n",
      "Epoch 321/1000\n",
      "59/59 [==============================] - 0s 1ms/step - loss: 0.5677 - val_loss: 0.5676\n",
      "Epoch 322/1000\n",
      "59/59 [==============================] - 0s 797us/step - loss: 0.5676 - val_loss: 0.5675\n",
      "Epoch 323/1000\n",
      "59/59 [==============================] - 0s 814us/step - loss: 0.5675 - val_loss: 0.5674\n",
      "Epoch 324/1000\n",
      "59/59 [==============================] - 0s 932us/step - loss: 0.5674 - val_loss: 0.5673\n",
      "Epoch 325/1000\n",
      "59/59 [==============================] - 0s 864us/step - loss: 0.5673 - val_loss: 0.5673\n",
      "Epoch 326/1000\n",
      "59/59 [==============================] - 0s 831us/step - loss: 0.5672 - val_loss: 0.5672\n",
      "Epoch 327/1000\n",
      "59/59 [==============================] - 0s 966us/step - loss: 0.5672 - val_loss: 0.5671\n",
      "Epoch 328/1000\n",
      "59/59 [==============================] - 0s 797us/step - loss: 0.5671 - val_loss: 0.5670\n",
      "Epoch 329/1000\n",
      "59/59 [==============================] - 0s 848us/step - loss: 0.5670 - val_loss: 0.5669\n",
      "Epoch 330/1000\n",
      "59/59 [==============================] - 0s 763us/step - loss: 0.5669 - val_loss: 0.5668\n",
      "Epoch 331/1000\n",
      "59/59 [==============================] - 0s 695us/step - loss: 0.5668 - val_loss: 0.5667\n",
      "Epoch 332/1000\n",
      "59/59 [==============================] - 0s 814us/step - loss: 0.5667 - val_loss: 0.5666\n",
      "Epoch 333/1000\n",
      "59/59 [==============================] - 0s 814us/step - loss: 0.5666 - val_loss: 0.5665\n",
      "Epoch 334/1000\n",
      "59/59 [==============================] - 0s 814us/step - loss: 0.5665 - val_loss: 0.5664\n",
      "Epoch 335/1000\n",
      "59/59 [==============================] - 0s 814us/step - loss: 0.5664 - val_loss: 0.5663\n",
      "Epoch 336/1000\n",
      "59/59 [==============================] - 0s 915us/step - loss: 0.5664 - val_loss: 0.5663\n",
      "Epoch 337/1000\n",
      "59/59 [==============================] - 0s 780us/step - loss: 0.5662 - val_loss: 0.5662\n",
      "Epoch 338/1000\n",
      "59/59 [==============================] - 0s 763us/step - loss: 0.5662 - val_loss: 0.5661\n",
      "Epoch 339/1000\n",
      "59/59 [==============================] - 0s 864us/step - loss: 0.5661 - val_loss: 0.5660\n",
      "Epoch 340/1000\n",
      "59/59 [==============================] - 0s 864us/step - loss: 0.5660 - val_loss: 0.5659\n",
      "Epoch 341/1000\n",
      "59/59 [==============================] - 0s 763us/step - loss: 0.5659 - val_loss: 0.5658\n",
      "Epoch 342/1000\n",
      "59/59 [==============================] - 0s 814us/step - loss: 0.5658 - val_loss: 0.5657\n",
      "Epoch 343/1000\n",
      "59/59 [==============================] - 0s 763us/step - loss: 0.5657 - val_loss: 0.5657\n",
      "Epoch 344/1000\n",
      "59/59 [==============================] - 0s 864us/step - loss: 0.5657 - val_loss: 0.5656\n",
      "Epoch 345/1000\n",
      "59/59 [==============================] - 0s 915us/step - loss: 0.5656 - val_loss: 0.5655\n",
      "Epoch 346/1000\n",
      "59/59 [==============================] - 0s 814us/step - loss: 0.5655 - val_loss: 0.5654\n",
      "Epoch 347/1000\n",
      "59/59 [==============================] - 0s 848us/step - loss: 0.5654 - val_loss: 0.5653\n",
      "Epoch 348/1000\n",
      "59/59 [==============================] - 0s 814us/step - loss: 0.5653 - val_loss: 0.5652\n",
      "Epoch 349/1000\n",
      "59/59 [==============================] - 0s 864us/step - loss: 0.5652 - val_loss: 0.5652\n",
      "Epoch 350/1000\n",
      "59/59 [==============================] - 0s 864us/step - loss: 0.5652 - val_loss: 0.5651\n",
      "Epoch 351/1000\n",
      "59/59 [==============================] - 0s 712us/step - loss: 0.5651 - val_loss: 0.5650\n",
      "Epoch 352/1000\n",
      "59/59 [==============================] - 0s 746us/step - loss: 0.5650 - val_loss: 0.5649\n",
      "Epoch 353/1000\n",
      "59/59 [==============================] - 0s 780us/step - loss: 0.5649 - val_loss: 0.5649\n",
      "Epoch 354/1000\n",
      "59/59 [==============================] - 0s 814us/step - loss: 0.5649 - val_loss: 0.5648\n",
      "Epoch 355/1000\n",
      "59/59 [==============================] - 0s 915us/step - loss: 0.5648 - val_loss: 0.5647\n",
      "Epoch 356/1000\n",
      "59/59 [==============================] - 0s 695us/step - loss: 0.5647 - val_loss: 0.5646\n",
      "Epoch 357/1000\n",
      "59/59 [==============================] - 0s 746us/step - loss: 0.5646 - val_loss: 0.5646\n",
      "Epoch 358/1000\n",
      "59/59 [==============================] - 0s 881us/step - loss: 0.5646 - val_loss: 0.5645\n",
      "Epoch 359/1000\n",
      "59/59 [==============================] - 0s 864us/step - loss: 0.5645 - val_loss: 0.5644\n",
      "Epoch 360/1000\n",
      "59/59 [==============================] - 0s 797us/step - loss: 0.5644 - val_loss: 0.5643\n",
      "Epoch 361/1000\n",
      "59/59 [==============================] - 0s 695us/step - loss: 0.5644 - val_loss: 0.5643\n",
      "Epoch 362/1000\n",
      "59/59 [==============================] - 0s 661us/step - loss: 0.5643 - val_loss: 0.5642\n",
      "Epoch 363/1000\n",
      "59/59 [==============================] - 0s 831us/step - loss: 0.5642 - val_loss: 0.5641\n",
      "Epoch 364/1000\n",
      "59/59 [==============================] - 0s 814us/step - loss: 0.5641 - val_loss: 0.5641\n",
      "Epoch 365/1000\n",
      "59/59 [==============================] - 0s 678us/step - loss: 0.5641 - val_loss: 0.5640\n",
      "Epoch 366/1000\n",
      "59/59 [==============================] - 0s 797us/step - loss: 0.5640 - val_loss: 0.5639\n",
      "Epoch 367/1000\n",
      "59/59 [==============================] - 0s 864us/step - loss: 0.5639 - val_loss: 0.5639\n",
      "Epoch 368/1000\n",
      "59/59 [==============================] - 0s 763us/step - loss: 0.5639 - val_loss: 0.5638\n",
      "Epoch 369/1000\n",
      "59/59 [==============================] - 0s 746us/step - loss: 0.5638 - val_loss: 0.5637\n",
      "Epoch 370/1000\n",
      "59/59 [==============================] - 0s 898us/step - loss: 0.5637 - val_loss: 0.5637\n",
      "Epoch 371/1000\n",
      "59/59 [==============================] - 0s 678us/step - loss: 0.5637 - val_loss: 0.5636\n",
      "Epoch 372/1000\n",
      "59/59 [==============================] - 0s 746us/step - loss: 0.5636 - val_loss: 0.5635\n",
      "Epoch 373/1000\n",
      "59/59 [==============================] - 0s 848us/step - loss: 0.5636 - val_loss: 0.5635\n",
      "Epoch 374/1000\n",
      "59/59 [==============================] - 0s 695us/step - loss: 0.5635 - val_loss: 0.5634\n",
      "Epoch 375/1000\n",
      "59/59 [==============================] - 0s 780us/step - loss: 0.5634 - val_loss: 0.5633\n",
      "Epoch 376/1000\n",
      "59/59 [==============================] - 0s 729us/step - loss: 0.5633 - val_loss: 0.5633\n",
      "Epoch 377/1000\n",
      "59/59 [==============================] - 0s 712us/step - loss: 0.5633 - val_loss: 0.5632\n",
      "Epoch 378/1000\n",
      "59/59 [==============================] - 0s 780us/step - loss: 0.5632 - val_loss: 0.5632\n",
      "Epoch 379/1000\n",
      "59/59 [==============================] - 0s 695us/step - loss: 0.5632 - val_loss: 0.5631\n",
      "Epoch 380/1000\n",
      "59/59 [==============================] - 0s 729us/step - loss: 0.5631 - val_loss: 0.5630\n",
      "Epoch 381/1000\n",
      "59/59 [==============================] - 0s 763us/step - loss: 0.5630 - val_loss: 0.5630\n",
      "Epoch 382/1000\n",
      "59/59 [==============================] - 0s 678us/step - loss: 0.5630 - val_loss: 0.5629\n",
      "Epoch 383/1000\n",
      "59/59 [==============================] - 0s 763us/step - loss: 0.5629 - val_loss: 0.5629\n",
      "Epoch 384/1000\n",
      "59/59 [==============================] - 0s 644us/step - loss: 0.5629 - val_loss: 0.5628\n",
      "Epoch 385/1000\n",
      "59/59 [==============================] - 0s 780us/step - loss: 0.5628 - val_loss: 0.5627\n",
      "Epoch 386/1000\n",
      "59/59 [==============================] - 0s 627us/step - loss: 0.5627 - val_loss: 0.5627\n",
      "Epoch 387/1000\n",
      "59/59 [==============================] - 0s 627us/step - loss: 0.5627 - val_loss: 0.5626\n",
      "Epoch 388/1000\n",
      "59/59 [==============================] - 0s 627us/step - loss: 0.5626 - val_loss: 0.5626\n",
      "Epoch 389/1000\n",
      "59/59 [==============================] - 0s 746us/step - loss: 0.5626 - val_loss: 0.5625\n",
      "Epoch 390/1000\n",
      "59/59 [==============================] - 0s 644us/step - loss: 0.5625 - val_loss: 0.5625\n",
      "Epoch 391/1000\n",
      "59/59 [==============================] - 0s 729us/step - loss: 0.5625 - val_loss: 0.5624\n",
      "Epoch 392/1000\n",
      "59/59 [==============================] - 0s 661us/step - loss: 0.5624 - val_loss: 0.5624\n",
      "Epoch 393/1000\n",
      "59/59 [==============================] - 0s 831us/step - loss: 0.5624 - val_loss: 0.5623\n",
      "Epoch 394/1000\n",
      "59/59 [==============================] - 0s 627us/step - loss: 0.5623 - val_loss: 0.5623\n",
      "Epoch 395/1000\n",
      "59/59 [==============================] - 0s 763us/step - loss: 0.5623 - val_loss: 0.5622\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 396/1000\n",
      "59/59 [==============================] - 0s 627us/step - loss: 0.5622 - val_loss: 0.5622\n",
      "Epoch 397/1000\n",
      "59/59 [==============================] - 0s 729us/step - loss: 0.5622 - val_loss: 0.5621\n",
      "Epoch 398/1000\n",
      "59/59 [==============================] - 0s 644us/step - loss: 0.5621 - val_loss: 0.5621\n",
      "Epoch 399/1000\n",
      "59/59 [==============================] - 0s 814us/step - loss: 0.5621 - val_loss: 0.5620\n",
      "Epoch 400/1000\n",
      "59/59 [==============================] - 0s 763us/step - loss: 0.5620 - val_loss: 0.5620\n",
      "Epoch 401/1000\n",
      "59/59 [==============================] - 0s 814us/step - loss: 0.5620 - val_loss: 0.5619\n",
      "Epoch 402/1000\n",
      "59/59 [==============================] - 0s 712us/step - loss: 0.5620 - val_loss: 0.5619\n",
      "Epoch 403/1000\n",
      "59/59 [==============================] - 0s 1ms/step - loss: 0.5619 - val_loss: 0.5618\n",
      "Epoch 404/1000\n",
      "59/59 [==============================] - 0s 797us/step - loss: 0.5618 - val_loss: 0.5618\n",
      "Epoch 405/1000\n",
      "59/59 [==============================] - 0s 932us/step - loss: 0.5618 - val_loss: 0.5617\n",
      "Epoch 406/1000\n",
      "59/59 [==============================] - 0s 949us/step - loss: 0.5617 - val_loss: 0.5617\n",
      "Epoch 407/1000\n",
      "59/59 [==============================] - 0s 814us/step - loss: 0.5617 - val_loss: 0.5616\n",
      "Epoch 408/1000\n",
      "59/59 [==============================] - 0s 763us/step - loss: 0.5617 - val_loss: 0.5616\n",
      "Epoch 409/1000\n",
      "59/59 [==============================] - 0s 746us/step - loss: 0.5616 - val_loss: 0.5616\n",
      "Epoch 410/1000\n",
      "59/59 [==============================] - 0s 644us/step - loss: 0.5616 - val_loss: 0.5615\n",
      "Epoch 411/1000\n",
      "59/59 [==============================] - 0s 966us/step - loss: 0.5615 - val_loss: 0.5615\n",
      "Epoch 412/1000\n",
      "59/59 [==============================] - 0s 729us/step - loss: 0.5615 - val_loss: 0.5614\n",
      "Epoch 413/1000\n",
      "59/59 [==============================] - 0s 932us/step - loss: 0.5614 - val_loss: 0.5614\n",
      "Epoch 414/1000\n",
      "59/59 [==============================] - 0s 712us/step - loss: 0.5614 - val_loss: 0.5613\n",
      "Epoch 415/1000\n",
      "59/59 [==============================] - 0s 644us/step - loss: 0.5613 - val_loss: 0.5613\n",
      "Epoch 416/1000\n",
      "59/59 [==============================] - 0s 881us/step - loss: 0.5613 - val_loss: 0.5613\n",
      "Epoch 417/1000\n",
      "59/59 [==============================] - 0s 763us/step - loss: 0.5613 - val_loss: 0.5612\n",
      "Epoch 418/1000\n",
      "59/59 [==============================] - 0s 881us/step - loss: 0.5612 - val_loss: 0.5612\n",
      "Epoch 419/1000\n",
      "59/59 [==============================] - 0s 915us/step - loss: 0.5612 - val_loss: 0.5611\n",
      "Epoch 420/1000\n",
      "59/59 [==============================] - 0s 848us/step - loss: 0.5612 - val_loss: 0.5611\n",
      "Epoch 421/1000\n",
      "59/59 [==============================] - 0s 712us/step - loss: 0.5611 - val_loss: 0.5611\n",
      "Epoch 422/1000\n",
      "59/59 [==============================] - 0s 1ms/step - loss: 0.5611 - val_loss: 0.5610\n",
      "Epoch 423/1000\n",
      "59/59 [==============================] - 0s 780us/step - loss: 0.5610 - val_loss: 0.5610\n",
      "Epoch 424/1000\n",
      "59/59 [==============================] - 0s 695us/step - loss: 0.5610 - val_loss: 0.5609\n",
      "Epoch 425/1000\n",
      "59/59 [==============================] - 0s 848us/step - loss: 0.5610 - val_loss: 0.5609\n",
      "Epoch 426/1000\n",
      "59/59 [==============================] - 0s 864us/step - loss: 0.5609 - val_loss: 0.5609\n",
      "Epoch 427/1000\n",
      "59/59 [==============================] - 0s 712us/step - loss: 0.5609 - val_loss: 0.5608\n",
      "Epoch 428/1000\n",
      "59/59 [==============================] - 0s 746us/step - loss: 0.5609 - val_loss: 0.5608\n",
      "Epoch 429/1000\n",
      "59/59 [==============================] - 0s 864us/step - loss: 0.5608 - val_loss: 0.5608\n",
      "Epoch 430/1000\n",
      "59/59 [==============================] - 0s 746us/step - loss: 0.5608 - val_loss: 0.5607\n",
      "Epoch 431/1000\n",
      "59/59 [==============================] - 0s 763us/step - loss: 0.5607 - val_loss: 0.5607\n",
      "Epoch 432/1000\n",
      "59/59 [==============================] - 0s 780us/step - loss: 0.5607 - val_loss: 0.5607\n",
      "Epoch 433/1000\n",
      "59/59 [==============================] - 0s 729us/step - loss: 0.5607 - val_loss: 0.5606\n",
      "Epoch 434/1000\n",
      "59/59 [==============================] - 0s 763us/step - loss: 0.5606 - val_loss: 0.5606\n",
      "Epoch 435/1000\n",
      "59/59 [==============================] - 0s 864us/step - loss: 0.5606 - val_loss: 0.5606\n",
      "Epoch 436/1000\n",
      "59/59 [==============================] - 0s 831us/step - loss: 0.5606 - val_loss: 0.5605\n",
      "Epoch 437/1000\n",
      "59/59 [==============================] - 0s 864us/step - loss: 0.5605 - val_loss: 0.5605\n",
      "Epoch 438/1000\n",
      "59/59 [==============================] - 0s 678us/step - loss: 0.5605 - val_loss: 0.5605\n",
      "Epoch 439/1000\n",
      "59/59 [==============================] - 0s 814us/step - loss: 0.5605 - val_loss: 0.5604\n",
      "Epoch 440/1000\n",
      "59/59 [==============================] - 0s 831us/step - loss: 0.5604 - val_loss: 0.5604\n",
      "Epoch 441/1000\n",
      "59/59 [==============================] - 0s 746us/step - loss: 0.5604 - val_loss: 0.5604\n",
      "Epoch 442/1000\n",
      "59/59 [==============================] - 0s 864us/step - loss: 0.5604 - val_loss: 0.5603\n",
      "Epoch 443/1000\n",
      "59/59 [==============================] - 0s 712us/step - loss: 0.5603 - val_loss: 0.5603\n",
      "Epoch 444/1000\n",
      "59/59 [==============================] - 0s 695us/step - loss: 0.5603 - val_loss: 0.5603\n",
      "Epoch 445/1000\n",
      "59/59 [==============================] - 0s 831us/step - loss: 0.5603 - val_loss: 0.5602\n",
      "Epoch 446/1000\n",
      "59/59 [==============================] - 0s 729us/step - loss: 0.5602 - val_loss: 0.5602\n",
      "Epoch 447/1000\n",
      "59/59 [==============================] - 0s 746us/step - loss: 0.5602 - val_loss: 0.5602\n",
      "Epoch 448/1000\n",
      "59/59 [==============================] - 0s 831us/step - loss: 0.5602 - val_loss: 0.5601\n",
      "Epoch 449/1000\n",
      "59/59 [==============================] - 0s 763us/step - loss: 0.5601 - val_loss: 0.5601\n",
      "Epoch 450/1000\n",
      "59/59 [==============================] - 0s 729us/step - loss: 0.5601 - val_loss: 0.5601\n",
      "Epoch 451/1000\n",
      "59/59 [==============================] - 0s 780us/step - loss: 0.5601 - val_loss: 0.5601\n",
      "Epoch 452/1000\n",
      "59/59 [==============================] - 0s 678us/step - loss: 0.5601 - val_loss: 0.5600\n",
      "Epoch 453/1000\n",
      "59/59 [==============================] - 0s 797us/step - loss: 0.5600 - val_loss: 0.5600\n",
      "Epoch 454/1000\n",
      "59/59 [==============================] - 0s 695us/step - loss: 0.5600 - val_loss: 0.5600\n",
      "Epoch 455/1000\n",
      "59/59 [==============================] - 0s 695us/step - loss: 0.5600 - val_loss: 0.5599\n",
      "Epoch 456/1000\n",
      "59/59 [==============================] - 0s 695us/step - loss: 0.5599 - val_loss: 0.5599\n",
      "Epoch 457/1000\n",
      "59/59 [==============================] - 0s 695us/step - loss: 0.5599 - val_loss: 0.5599\n",
      "Epoch 458/1000\n",
      "59/59 [==============================] - 0s 797us/step - loss: 0.5599 - val_loss: 0.5599\n",
      "Epoch 459/1000\n",
      "59/59 [==============================] - 0s 797us/step - loss: 0.5599 - val_loss: 0.5598\n",
      "Epoch 460/1000\n",
      "59/59 [==============================] - 0s 627us/step - loss: 0.5598 - val_loss: 0.5598\n",
      "Epoch 461/1000\n",
      "59/59 [==============================] - 0s 864us/step - loss: 0.5598 - val_loss: 0.5598\n",
      "Epoch 462/1000\n",
      "59/59 [==============================] - 0s 746us/step - loss: 0.5598 - val_loss: 0.5598\n",
      "Epoch 463/1000\n",
      "59/59 [==============================] - 0s 729us/step - loss: 0.5598 - val_loss: 0.5597\n",
      "Epoch 464/1000\n",
      "59/59 [==============================] - 0s 864us/step - loss: 0.5597 - val_loss: 0.5597\n",
      "Epoch 465/1000\n",
      "59/59 [==============================] - 0s 814us/step - loss: 0.5597 - val_loss: 0.5597\n",
      "Epoch 466/1000\n",
      "59/59 [==============================] - 0s 695us/step - loss: 0.5597 - val_loss: 0.5597\n",
      "Epoch 467/1000\n",
      "59/59 [==============================] - 0s 644us/step - loss: 0.5597 - val_loss: 0.5596\n",
      "Epoch 468/1000\n",
      "59/59 [==============================] - 0s 746us/step - loss: 0.5596 - val_loss: 0.5596\n",
      "Epoch 469/1000\n",
      "59/59 [==============================] - 0s 644us/step - loss: 0.5596 - val_loss: 0.5596\n",
      "Epoch 470/1000\n",
      "59/59 [==============================] - 0s 644us/step - loss: 0.5596 - val_loss: 0.5596\n",
      "Epoch 471/1000\n",
      "59/59 [==============================] - 0s 780us/step - loss: 0.5596 - val_loss: 0.5595\n",
      "Epoch 472/1000\n",
      "59/59 [==============================] - 0s 678us/step - loss: 0.5596 - val_loss: 0.5595\n",
      "Epoch 473/1000\n",
      "59/59 [==============================] - 0s 678us/step - loss: 0.5595 - val_loss: 0.5595\n",
      "Epoch 474/1000\n",
      "59/59 [==============================] - 0s 627us/step - loss: 0.5595 - val_loss: 0.5595\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 475/1000\n",
      "59/59 [==============================] - 0s 729us/step - loss: 0.5595 - val_loss: 0.5594\n",
      "Epoch 476/1000\n",
      "59/59 [==============================] - 0s 729us/step - loss: 0.5594 - val_loss: 0.5594\n",
      "Epoch 477/1000\n",
      "59/59 [==============================] - 0s 661us/step - loss: 0.5594 - val_loss: 0.5594\n",
      "Epoch 478/1000\n",
      "59/59 [==============================] - 0s 661us/step - loss: 0.5594 - val_loss: 0.5594\n",
      "Epoch 479/1000\n",
      "59/59 [==============================] - 0s 729us/step - loss: 0.5594 - val_loss: 0.5594\n",
      "Epoch 480/1000\n",
      "59/59 [==============================] - 0s 1ms/step - loss: 0.5594 - val_loss: 0.5593\n",
      "Epoch 481/1000\n",
      "59/59 [==============================] - 0s 780us/step - loss: 0.5593 - val_loss: 0.5593\n",
      "Epoch 482/1000\n",
      "59/59 [==============================] - 0s 915us/step - loss: 0.5593 - val_loss: 0.5593\n",
      "Epoch 483/1000\n",
      "59/59 [==============================] - 0s 966us/step - loss: 0.5593 - val_loss: 0.5593\n",
      "Epoch 484/1000\n",
      "59/59 [==============================] - 0s 780us/step - loss: 0.5593 - val_loss: 0.5592\n",
      "Epoch 485/1000\n",
      "59/59 [==============================] - 0s 881us/step - loss: 0.5592 - val_loss: 0.5592\n",
      "Epoch 486/1000\n",
      "59/59 [==============================] - 0s 780us/step - loss: 0.5592 - val_loss: 0.5592\n",
      "Epoch 487/1000\n",
      "59/59 [==============================] - 0s 746us/step - loss: 0.5592 - val_loss: 0.5592\n",
      "Epoch 488/1000\n",
      "59/59 [==============================] - 0s 780us/step - loss: 0.5592 - val_loss: 0.5592\n",
      "Epoch 489/1000\n",
      "59/59 [==============================] - 0s 797us/step - loss: 0.5592 - val_loss: 0.5591\n",
      "Epoch 490/1000\n",
      "59/59 [==============================] - 0s 780us/step - loss: 0.5591 - val_loss: 0.5591\n",
      "Epoch 491/1000\n",
      "59/59 [==============================] - 0s 729us/step - loss: 0.5591 - val_loss: 0.5591\n",
      "Epoch 492/1000\n",
      "59/59 [==============================] - 0s 746us/step - loss: 0.5591 - val_loss: 0.5591\n",
      "Epoch 493/1000\n",
      "59/59 [==============================] - 0s 898us/step - loss: 0.5591 - val_loss: 0.5591\n",
      "Epoch 494/1000\n",
      "59/59 [==============================] - 0s 746us/step - loss: 0.5591 - val_loss: 0.5590\n",
      "Epoch 495/1000\n",
      "59/59 [==============================] - 0s 898us/step - loss: 0.5590 - val_loss: 0.5590\n",
      "Epoch 496/1000\n",
      "59/59 [==============================] - 0s 864us/step - loss: 0.5590 - val_loss: 0.5590\n",
      "Epoch 497/1000\n",
      "59/59 [==============================] - 0s 780us/step - loss: 0.5590 - val_loss: 0.5590\n",
      "Epoch 498/1000\n",
      "59/59 [==============================] - 0s 848us/step - loss: 0.5590 - val_loss: 0.5590\n",
      "Epoch 499/1000\n",
      "59/59 [==============================] - 0s 881us/step - loss: 0.5590 - val_loss: 0.5589\n",
      "Epoch 500/1000\n",
      "59/59 [==============================] - 0s 848us/step - loss: 0.5589 - val_loss: 0.5589\n",
      "Epoch 501/1000\n",
      "59/59 [==============================] - 0s 814us/step - loss: 0.5589 - val_loss: 0.5589\n",
      "Epoch 502/1000\n",
      "59/59 [==============================] - 0s 763us/step - loss: 0.5589 - val_loss: 0.5589\n",
      "Epoch 503/1000\n",
      "59/59 [==============================] - 0s 712us/step - loss: 0.5589 - val_loss: 0.5589\n",
      "Epoch 504/1000\n",
      "59/59 [==============================] - 0s 848us/step - loss: 0.5589 - val_loss: 0.5588\n",
      "Epoch 505/1000\n",
      "59/59 [==============================] - 0s 729us/step - loss: 0.5589 - val_loss: 0.5588\n",
      "Epoch 506/1000\n",
      "59/59 [==============================] - 0s 729us/step - loss: 0.5588 - val_loss: 0.5588\n",
      "Epoch 507/1000\n",
      "59/59 [==============================] - 0s 831us/step - loss: 0.5588 - val_loss: 0.5588\n",
      "Epoch 508/1000\n",
      "59/59 [==============================] - 0s 712us/step - loss: 0.5588 - val_loss: 0.5588\n",
      "Epoch 509/1000\n",
      "59/59 [==============================] - 0s 729us/step - loss: 0.5588 - val_loss: 0.5587\n",
      "Epoch 510/1000\n",
      "59/59 [==============================] - 0s 746us/step - loss: 0.5588 - val_loss: 0.5587\n",
      "Epoch 511/1000\n",
      "59/59 [==============================] - 0s 831us/step - loss: 0.5587 - val_loss: 0.5587\n",
      "Epoch 512/1000\n",
      "59/59 [==============================] - 0s 814us/step - loss: 0.5587 - val_loss: 0.5587\n",
      "Epoch 513/1000\n",
      "59/59 [==============================] - 0s 746us/step - loss: 0.5587 - val_loss: 0.5587\n",
      "Epoch 514/1000\n",
      "59/59 [==============================] - 0s 729us/step - loss: 0.5587 - val_loss: 0.5586\n",
      "Epoch 515/1000\n",
      "59/59 [==============================] - 0s 797us/step - loss: 0.5587 - val_loss: 0.5586\n",
      "Epoch 516/1000\n",
      "59/59 [==============================] - 0s 797us/step - loss: 0.5586 - val_loss: 0.5586\n",
      "Epoch 517/1000\n",
      "59/59 [==============================] - 0s 678us/step - loss: 0.5586 - val_loss: 0.5586\n",
      "Epoch 518/1000\n",
      "59/59 [==============================] - 0s 814us/step - loss: 0.5586 - val_loss: 0.5586\n",
      "Epoch 519/1000\n",
      "59/59 [==============================] - 0s 831us/step - loss: 0.5586 - val_loss: 0.5586\n",
      "Epoch 520/1000\n",
      "59/59 [==============================] - 0s 729us/step - loss: 0.5586 - val_loss: 0.5585\n",
      "Epoch 521/1000\n",
      "59/59 [==============================] - 0s 881us/step - loss: 0.5586 - val_loss: 0.5585\n",
      "Epoch 522/1000\n",
      "59/59 [==============================] - 0s 797us/step - loss: 0.5585 - val_loss: 0.5585\n",
      "Epoch 523/1000\n",
      "59/59 [==============================] - 0s 746us/step - loss: 0.5585 - val_loss: 0.5585\n",
      "Epoch 524/1000\n",
      "59/59 [==============================] - 0s 831us/step - loss: 0.5585 - val_loss: 0.5585\n",
      "Epoch 525/1000\n",
      "59/59 [==============================] - 0s 831us/step - loss: 0.5585 - val_loss: 0.5585\n",
      "Epoch 526/1000\n",
      "59/59 [==============================] - 0s 831us/step - loss: 0.5585 - val_loss: 0.5584\n",
      "Epoch 527/1000\n",
      "59/59 [==============================] - 0s 661us/step - loss: 0.5584 - val_loss: 0.5584\n",
      "Epoch 528/1000\n",
      "59/59 [==============================] - 0s 848us/step - loss: 0.5584 - val_loss: 0.5584\n",
      "Epoch 529/1000\n",
      "59/59 [==============================] - 0s 695us/step - loss: 0.5584 - val_loss: 0.5584\n",
      "Epoch 530/1000\n",
      "59/59 [==============================] - 0s 746us/step - loss: 0.5584 - val_loss: 0.5584\n",
      "Epoch 531/1000\n",
      "59/59 [==============================] - 0s 881us/step - loss: 0.5584 - val_loss: 0.5583\n",
      "Epoch 532/1000\n",
      "59/59 [==============================] - 0s 814us/step - loss: 0.5584 - val_loss: 0.5583\n",
      "Epoch 533/1000\n",
      "59/59 [==============================] - 0s 678us/step - loss: 0.5584 - val_loss: 0.5583\n",
      "Epoch 534/1000\n",
      "59/59 [==============================] - 0s 881us/step - loss: 0.5583 - val_loss: 0.5583\n",
      "Epoch 535/1000\n",
      "59/59 [==============================] - 0s 780us/step - loss: 0.5583 - val_loss: 0.5583\n",
      "Epoch 536/1000\n",
      "59/59 [==============================] - 0s 695us/step - loss: 0.5583 - val_loss: 0.5583\n",
      "Epoch 537/1000\n",
      "59/59 [==============================] - 0s 746us/step - loss: 0.5583 - val_loss: 0.5583\n",
      "Epoch 538/1000\n",
      "59/59 [==============================] - 0s 678us/step - loss: 0.5583 - val_loss: 0.5582\n",
      "Epoch 539/1000\n",
      "59/59 [==============================] - 0s 780us/step - loss: 0.5582 - val_loss: 0.5582\n",
      "Epoch 540/1000\n",
      "59/59 [==============================] - 0s 695us/step - loss: 0.5582 - val_loss: 0.5582\n",
      "Epoch 541/1000\n",
      "59/59 [==============================] - 0s 712us/step - loss: 0.5582 - val_loss: 0.5582\n",
      "Epoch 542/1000\n",
      "59/59 [==============================] - 0s 712us/step - loss: 0.5582 - val_loss: 0.5582\n",
      "Epoch 543/1000\n",
      "59/59 [==============================] - 0s 644us/step - loss: 0.5582 - val_loss: 0.5582\n",
      "Epoch 544/1000\n",
      "59/59 [==============================] - 0s 780us/step - loss: 0.5582 - val_loss: 0.5581\n",
      "Epoch 545/1000\n",
      "59/59 [==============================] - 0s 627us/step - loss: 0.5581 - val_loss: 0.5581\n",
      "Epoch 546/1000\n",
      "59/59 [==============================] - 0s 780us/step - loss: 0.5581 - val_loss: 0.5581\n",
      "Epoch 547/1000\n",
      "59/59 [==============================] - 0s 712us/step - loss: 0.5581 - val_loss: 0.5581\n",
      "Epoch 548/1000\n",
      "59/59 [==============================] - 0s 712us/step - loss: 0.5581 - val_loss: 0.5581\n",
      "Epoch 549/1000\n",
      "59/59 [==============================] - 0s 797us/step - loss: 0.5581 - val_loss: 0.5581\n",
      "Epoch 550/1000\n",
      "59/59 [==============================] - 0s 695us/step - loss: 0.5581 - val_loss: 0.5580\n",
      "Epoch 551/1000\n",
      "59/59 [==============================] - 0s 881us/step - loss: 0.5580 - val_loss: 0.5580\n",
      "Epoch 552/1000\n",
      "59/59 [==============================] - 0s 814us/step - loss: 0.5580 - val_loss: 0.5580\n",
      "Epoch 553/1000\n",
      "59/59 [==============================] - 0s 729us/step - loss: 0.5580 - val_loss: 0.5580\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 554/1000\n",
      "59/59 [==============================] - 0s 797us/step - loss: 0.5580 - val_loss: 0.5580\n",
      "Epoch 555/1000\n",
      "59/59 [==============================] - 0s 746us/step - loss: 0.5580 - val_loss: 0.5580\n",
      "Epoch 556/1000\n",
      "59/59 [==============================] - 0s 746us/step - loss: 0.5580 - val_loss: 0.5579\n",
      "Epoch 557/1000\n",
      "59/59 [==============================] - 0s 661us/step - loss: 0.5579 - val_loss: 0.5579\n",
      "Epoch 558/1000\n",
      "59/59 [==============================] - 0s 814us/step - loss: 0.5579 - val_loss: 0.5579\n",
      "Epoch 559/1000\n",
      "59/59 [==============================] - 0s 864us/step - loss: 0.5579 - val_loss: 0.5579\n",
      "Epoch 560/1000\n",
      "59/59 [==============================] - 0s 797us/step - loss: 0.5579 - val_loss: 0.5579\n",
      "Epoch 561/1000\n",
      "59/59 [==============================] - 0s 966us/step - loss: 0.5579 - val_loss: 0.5579\n",
      "Epoch 562/1000\n",
      "59/59 [==============================] - 0s 881us/step - loss: 0.5579 - val_loss: 0.5578\n",
      "Epoch 563/1000\n",
      "59/59 [==============================] - 0s 1ms/step - loss: 0.5579 - val_loss: 0.5578\n",
      "Epoch 564/1000\n",
      "59/59 [==============================] - 0s 763us/step - loss: 0.5578 - val_loss: 0.5578\n",
      "Epoch 565/1000\n",
      "59/59 [==============================] - 0s 831us/step - loss: 0.5578 - val_loss: 0.5578\n",
      "Epoch 566/1000\n",
      "59/59 [==============================] - 0s 746us/step - loss: 0.5578 - val_loss: 0.5578\n",
      "Epoch 567/1000\n",
      "59/59 [==============================] - 0s 848us/step - loss: 0.5578 - val_loss: 0.5578\n",
      "Epoch 568/1000\n",
      "59/59 [==============================] - 0s 831us/step - loss: 0.5578 - val_loss: 0.5578\n",
      "Epoch 569/1000\n",
      "59/59 [==============================] - 0s 797us/step - loss: 0.5578 - val_loss: 0.5577\n",
      "Epoch 570/1000\n",
      "59/59 [==============================] - 0s 915us/step - loss: 0.5578 - val_loss: 0.5577\n",
      "Epoch 571/1000\n",
      "59/59 [==============================] - 0s 831us/step - loss: 0.5577 - val_loss: 0.5577\n",
      "Epoch 572/1000\n",
      "59/59 [==============================] - 0s 797us/step - loss: 0.5577 - val_loss: 0.5577\n",
      "Epoch 573/1000\n",
      "59/59 [==============================] - 0s 898us/step - loss: 0.5577 - val_loss: 0.5577\n",
      "Epoch 574/1000\n",
      "59/59 [==============================] - 0s 814us/step - loss: 0.5577 - val_loss: 0.5577\n",
      "Epoch 575/1000\n",
      "59/59 [==============================] - 0s 881us/step - loss: 0.5577 - val_loss: 0.5576\n",
      "Epoch 576/1000\n",
      "59/59 [==============================] - 0s 797us/step - loss: 0.5577 - val_loss: 0.5576\n",
      "Epoch 577/1000\n",
      "59/59 [==============================] - 0s 797us/step - loss: 0.5576 - val_loss: 0.5576\n",
      "Epoch 578/1000\n",
      "59/59 [==============================] - 0s 848us/step - loss: 0.5576 - val_loss: 0.5576\n",
      "Epoch 579/1000\n",
      "59/59 [==============================] - 0s 814us/step - loss: 0.5576 - val_loss: 0.5576\n",
      "Epoch 580/1000\n",
      "59/59 [==============================] - 0s 814us/step - loss: 0.5576 - val_loss: 0.5576\n",
      "Epoch 581/1000\n",
      "59/59 [==============================] - 0s 915us/step - loss: 0.5576 - val_loss: 0.5576\n",
      "Epoch 582/1000\n",
      "59/59 [==============================] - 0s 898us/step - loss: 0.5576 - val_loss: 0.5575\n",
      "Epoch 583/1000\n",
      "59/59 [==============================] - 0s 780us/step - loss: 0.5576 - val_loss: 0.5575\n",
      "Epoch 584/1000\n",
      "59/59 [==============================] - 0s 746us/step - loss: 0.5575 - val_loss: 0.5575\n",
      "Epoch 585/1000\n",
      "59/59 [==============================] - 0s 746us/step - loss: 0.5575 - val_loss: 0.5575\n",
      "Epoch 586/1000\n",
      "59/59 [==============================] - 0s 695us/step - loss: 0.5575 - val_loss: 0.5575\n",
      "Epoch 587/1000\n",
      "59/59 [==============================] - 0s 712us/step - loss: 0.5575 - val_loss: 0.5575\n",
      "Epoch 588/1000\n",
      "59/59 [==============================] - 0s 763us/step - loss: 0.5575 - val_loss: 0.5574\n",
      "Epoch 589/1000\n",
      "59/59 [==============================] - 0s 763us/step - loss: 0.5575 - val_loss: 0.5574\n",
      "Epoch 590/1000\n",
      "59/59 [==============================] - 0s 729us/step - loss: 0.5574 - val_loss: 0.5574\n",
      "Epoch 591/1000\n",
      "59/59 [==============================] - 0s 678us/step - loss: 0.5574 - val_loss: 0.5574\n",
      "Epoch 592/1000\n",
      "59/59 [==============================] - 0s 678us/step - loss: 0.5574 - val_loss: 0.5574\n",
      "Epoch 593/1000\n",
      "59/59 [==============================] - 0s 881us/step - loss: 0.5574 - val_loss: 0.5574\n",
      "Epoch 594/1000\n",
      "59/59 [==============================] - 0s 763us/step - loss: 0.5574 - val_loss: 0.5574\n",
      "Epoch 595/1000\n",
      "59/59 [==============================] - 0s 898us/step - loss: 0.5574 - val_loss: 0.5573\n",
      "Epoch 596/1000\n",
      "59/59 [==============================] - 0s 695us/step - loss: 0.5573 - val_loss: 0.5573\n",
      "Epoch 597/1000\n",
      "59/59 [==============================] - 0s 814us/step - loss: 0.5574 - val_loss: 0.5573\n",
      "Epoch 598/1000\n",
      "59/59 [==============================] - 0s 780us/step - loss: 0.5573 - val_loss: 0.5573\n",
      "Epoch 599/1000\n",
      "59/59 [==============================] - 0s 763us/step - loss: 0.5573 - val_loss: 0.5573\n",
      "Epoch 600/1000\n",
      "59/59 [==============================] - 0s 729us/step - loss: 0.5573 - val_loss: 0.5573\n",
      "Epoch 601/1000\n",
      "59/59 [==============================] - 0s 780us/step - loss: 0.5573 - val_loss: 0.5573\n",
      "Epoch 602/1000\n",
      "59/59 [==============================] - 0s 864us/step - loss: 0.5573 - val_loss: 0.5572\n",
      "Epoch 603/1000\n",
      "59/59 [==============================] - 0s 848us/step - loss: 0.5572 - val_loss: 0.5572\n",
      "Epoch 604/1000\n",
      "59/59 [==============================] - 0s 831us/step - loss: 0.5572 - val_loss: 0.5572\n",
      "Epoch 605/1000\n",
      "59/59 [==============================] - 0s 746us/step - loss: 0.5572 - val_loss: 0.5572\n",
      "Epoch 606/1000\n",
      "59/59 [==============================] - 0s 695us/step - loss: 0.5572 - val_loss: 0.5572\n",
      "Epoch 607/1000\n",
      "59/59 [==============================] - 0s 848us/step - loss: 0.5572 - val_loss: 0.5572\n",
      "Epoch 608/1000\n",
      "59/59 [==============================] - 0s 763us/step - loss: 0.5572 - val_loss: 0.5571\n",
      "Epoch 609/1000\n",
      "59/59 [==============================] - 0s 712us/step - loss: 0.5572 - val_loss: 0.5571\n",
      "Epoch 610/1000\n",
      "59/59 [==============================] - 0s 814us/step - loss: 0.5571 - val_loss: 0.5571\n",
      "Epoch 611/1000\n",
      "59/59 [==============================] - 0s 729us/step - loss: 0.5571 - val_loss: 0.5571\n",
      "Epoch 612/1000\n",
      "59/59 [==============================] - 0s 797us/step - loss: 0.5571 - val_loss: 0.5571\n",
      "Epoch 613/1000\n",
      "59/59 [==============================] - 0s 797us/step - loss: 0.5571 - val_loss: 0.5571\n",
      "Epoch 614/1000\n",
      "59/59 [==============================] - 0s 695us/step - loss: 0.5571 - val_loss: 0.5571\n",
      "Epoch 615/1000\n",
      "59/59 [==============================] - 0s 864us/step - loss: 0.5571 - val_loss: 0.5570\n",
      "Epoch 616/1000\n",
      "59/59 [==============================] - 0s 695us/step - loss: 0.5570 - val_loss: 0.5570\n",
      "Epoch 617/1000\n",
      "59/59 [==============================] - 0s 780us/step - loss: 0.5570 - val_loss: 0.5570\n",
      "Epoch 618/1000\n",
      "59/59 [==============================] - 0s 644us/step - loss: 0.5570 - val_loss: 0.5570\n",
      "Epoch 619/1000\n",
      "59/59 [==============================] - 0s 729us/step - loss: 0.5570 - val_loss: 0.5570\n",
      "Epoch 620/1000\n",
      "59/59 [==============================] - 0s 780us/step - loss: 0.5570 - val_loss: 0.5570\n",
      "Epoch 621/1000\n",
      "59/59 [==============================] - 0s 678us/step - loss: 0.5570 - val_loss: 0.5570\n",
      "Epoch 622/1000\n",
      "59/59 [==============================] - 0s 797us/step - loss: 0.5570 - val_loss: 0.5569\n",
      "Epoch 623/1000\n",
      "59/59 [==============================] - 0s 966us/step - loss: 0.5569 - val_loss: 0.5569\n",
      "Epoch 624/1000\n",
      "59/59 [==============================] - 0s 814us/step - loss: 0.5569 - val_loss: 0.5569\n",
      "Epoch 625/1000\n",
      "59/59 [==============================] - 0s 797us/step - loss: 0.5569 - val_loss: 0.5569\n",
      "Epoch 626/1000\n",
      "59/59 [==============================] - 0s 712us/step - loss: 0.5569 - val_loss: 0.5569\n",
      "Epoch 627/1000\n",
      "59/59 [==============================] - 0s 678us/step - loss: 0.5569 - val_loss: 0.5569\n",
      "Epoch 628/1000\n",
      "59/59 [==============================] - 0s 797us/step - loss: 0.5569 - val_loss: 0.5568\n",
      "Epoch 629/1000\n",
      "59/59 [==============================] - 0s 712us/step - loss: 0.5569 - val_loss: 0.5568\n",
      "Epoch 630/1000\n",
      "59/59 [==============================] - 0s 746us/step - loss: 0.5569 - val_loss: 0.5568\n",
      "Epoch 631/1000\n",
      "59/59 [==============================] - 0s 712us/step - loss: 0.5568 - val_loss: 0.5568\n",
      "Epoch 632/1000\n",
      "59/59 [==============================] - 0s 695us/step - loss: 0.5568 - val_loss: 0.5568\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 633/1000\n",
      "59/59 [==============================] - 0s 695us/step - loss: 0.5568 - val_loss: 0.5568\n",
      "Epoch 634/1000\n",
      "59/59 [==============================] - 0s 729us/step - loss: 0.5568 - val_loss: 0.5568\n",
      "Epoch 635/1000\n",
      "59/59 [==============================] - 0s 661us/step - loss: 0.5568 - val_loss: 0.5567\n",
      "Epoch 636/1000\n",
      "59/59 [==============================] - 0s 661us/step - loss: 0.5568 - val_loss: 0.5567\n",
      "Epoch 637/1000\n",
      "59/59 [==============================] - 0s 898us/step - loss: 0.5567 - val_loss: 0.5567\n",
      "Epoch 638/1000\n",
      "59/59 [==============================] - 0s 814us/step - loss: 0.5567 - val_loss: 0.5567\n",
      "Epoch 639/1000\n",
      "59/59 [==============================] - 0s 1ms/step - loss: 0.5567 - val_loss: 0.5567\n",
      "Epoch 640/1000\n",
      "59/59 [==============================] - 0s 780us/step - loss: 0.5567 - val_loss: 0.5567\n",
      "Epoch 641/1000\n",
      "59/59 [==============================] - 0s 848us/step - loss: 0.5567 - val_loss: 0.5567\n",
      "Epoch 642/1000\n",
      "59/59 [==============================] - 0s 797us/step - loss: 0.5567 - val_loss: 0.5566\n",
      "Epoch 643/1000\n",
      "59/59 [==============================] - 0s 881us/step - loss: 0.5566 - val_loss: 0.5566\n",
      "Epoch 644/1000\n",
      "59/59 [==============================] - 0s 864us/step - loss: 0.5566 - val_loss: 0.5566\n",
      "Epoch 645/1000\n",
      "59/59 [==============================] - 0s 864us/step - loss: 0.5566 - val_loss: 0.5566\n",
      "Epoch 646/1000\n",
      "59/59 [==============================] - 0s 780us/step - loss: 0.5566 - val_loss: 0.5566\n",
      "Epoch 647/1000\n",
      "59/59 [==============================] - 0s 814us/step - loss: 0.5566 - val_loss: 0.5566\n",
      "Epoch 648/1000\n",
      "59/59 [==============================] - 0s 848us/step - loss: 0.5566 - val_loss: 0.5565\n",
      "Epoch 649/1000\n",
      "59/59 [==============================] - 0s 831us/step - loss: 0.5566 - val_loss: 0.5565\n",
      "Epoch 650/1000\n",
      "59/59 [==============================] - 0s 780us/step - loss: 0.5565 - val_loss: 0.5565\n",
      "Epoch 651/1000\n",
      "59/59 [==============================] - 0s 915us/step - loss: 0.5565 - val_loss: 0.5565\n",
      "Epoch 652/1000\n",
      "59/59 [==============================] - 0s 712us/step - loss: 0.5565 - val_loss: 0.5565\n",
      "Epoch 653/1000\n",
      "59/59 [==============================] - 0s 712us/step - loss: 0.5565 - val_loss: 0.5565\n",
      "Epoch 654/1000\n",
      "59/59 [==============================] - 0s 797us/step - loss: 0.5565 - val_loss: 0.5565\n",
      "Epoch 655/1000\n",
      "59/59 [==============================] - 0s 848us/step - loss: 0.5565 - val_loss: 0.5564\n",
      "Epoch 656/1000\n",
      "59/59 [==============================] - 0s 881us/step - loss: 0.5564 - val_loss: 0.5564\n",
      "Epoch 657/1000\n",
      "59/59 [==============================] - 0s 831us/step - loss: 0.5564 - val_loss: 0.5564\n",
      "Epoch 658/1000\n",
      "59/59 [==============================] - 0s 881us/step - loss: 0.5564 - val_loss: 0.5564\n",
      "Epoch 659/1000\n",
      "59/59 [==============================] - 0s 763us/step - loss: 0.5564 - val_loss: 0.5564\n",
      "Epoch 660/1000\n",
      "59/59 [==============================] - 0s 780us/step - loss: 0.5564 - val_loss: 0.5564\n",
      "Epoch 661/1000\n",
      "59/59 [==============================] - 0s 746us/step - loss: 0.5564 - val_loss: 0.5564\n",
      "Epoch 662/1000\n",
      "59/59 [==============================] - 0s 831us/step - loss: 0.5564 - val_loss: 0.5563\n",
      "Epoch 663/1000\n",
      "59/59 [==============================] - 0s 881us/step - loss: 0.5564 - val_loss: 0.5563\n",
      "Epoch 664/1000\n",
      "59/59 [==============================] - 0s 898us/step - loss: 0.5563 - val_loss: 0.5563\n",
      "Epoch 665/1000\n",
      "59/59 [==============================] - ETA: 0s - loss: 0.554 - 0s 746us/step - loss: 0.5563 - val_loss: 0.5563\n",
      "Epoch 666/1000\n",
      "59/59 [==============================] - 0s 814us/step - loss: 0.5563 - val_loss: 0.5563\n",
      "Epoch 667/1000\n",
      "59/59 [==============================] - 0s 864us/step - loss: 0.5563 - val_loss: 0.5563\n",
      "Epoch 668/1000\n",
      "59/59 [==============================] - 0s 780us/step - loss: 0.5563 - val_loss: 0.5562\n",
      "Epoch 669/1000\n",
      "59/59 [==============================] - 0s 864us/step - loss: 0.5563 - val_loss: 0.5562\n",
      "Epoch 670/1000\n",
      "59/59 [==============================] - 0s 966us/step - loss: 0.5562 - val_loss: 0.5562\n",
      "Epoch 671/1000\n",
      "59/59 [==============================] - 0s 848us/step - loss: 0.5562 - val_loss: 0.5562\n",
      "Epoch 672/1000\n",
      "59/59 [==============================] - 0s 864us/step - loss: 0.5562 - val_loss: 0.5562\n",
      "Epoch 673/1000\n",
      "59/59 [==============================] - 0s 712us/step - loss: 0.5562 - val_loss: 0.5562\n",
      "Epoch 674/1000\n",
      "59/59 [==============================] - 0s 712us/step - loss: 0.5562 - val_loss: 0.5562\n",
      "Epoch 675/1000\n",
      "59/59 [==============================] - 0s 848us/step - loss: 0.5562 - val_loss: 0.5561\n",
      "Epoch 676/1000\n",
      "59/59 [==============================] - 0s 780us/step - loss: 0.5562 - val_loss: 0.5561\n",
      "Epoch 677/1000\n",
      "59/59 [==============================] - 0s 729us/step - loss: 0.5561 - val_loss: 0.5561\n",
      "Epoch 678/1000\n",
      "59/59 [==============================] - 0s 814us/step - loss: 0.5561 - val_loss: 0.5561\n",
      "Epoch 679/1000\n",
      "59/59 [==============================] - 0s 814us/step - loss: 0.5561 - val_loss: 0.5561\n",
      "Epoch 680/1000\n",
      "59/59 [==============================] - 0s 729us/step - loss: 0.5561 - val_loss: 0.5561\n",
      "Epoch 681/1000\n",
      "59/59 [==============================] - 0s 780us/step - loss: 0.5561 - val_loss: 0.5561\n",
      "Epoch 682/1000\n",
      "59/59 [==============================] - 0s 898us/step - loss: 0.5561 - val_loss: 0.5560\n",
      "Epoch 683/1000\n",
      "59/59 [==============================] - 0s 848us/step - loss: 0.5561 - val_loss: 0.5560\n",
      "Epoch 684/1000\n",
      "59/59 [==============================] - 0s 729us/step - loss: 0.5560 - val_loss: 0.5560\n",
      "Epoch 685/1000\n",
      "59/59 [==============================] - 0s 678us/step - loss: 0.5560 - val_loss: 0.5560\n",
      "Epoch 686/1000\n",
      "59/59 [==============================] - 0s 881us/step - loss: 0.5560 - val_loss: 0.5560\n",
      "Epoch 687/1000\n",
      "59/59 [==============================] - 0s 831us/step - loss: 0.5560 - val_loss: 0.5560\n",
      "Epoch 688/1000\n",
      "59/59 [==============================] - 0s 797us/step - loss: 0.5560 - val_loss: 0.5559\n",
      "Epoch 689/1000\n",
      "59/59 [==============================] - 0s 746us/step - loss: 0.5560 - val_loss: 0.5559\n",
      "Epoch 690/1000\n",
      "59/59 [==============================] - 0s 797us/step - loss: 0.5559 - val_loss: 0.5559\n",
      "Epoch 691/1000\n",
      "59/59 [==============================] - 0s 644us/step - loss: 0.5559 - val_loss: 0.5559\n",
      "Epoch 692/1000\n",
      "59/59 [==============================] - 0s 780us/step - loss: 0.5559 - val_loss: 0.5559\n",
      "Epoch 693/1000\n",
      "59/59 [==============================] - 0s 712us/step - loss: 0.5559 - val_loss: 0.5559\n",
      "Epoch 694/1000\n",
      "59/59 [==============================] - 0s 831us/step - loss: 0.5559 - val_loss: 0.5559\n",
      "Epoch 695/1000\n",
      "59/59 [==============================] - 0s 814us/step - loss: 0.5559 - val_loss: 0.5558\n",
      "Epoch 696/1000\n",
      "59/59 [==============================] - 0s 644us/step - loss: 0.5558 - val_loss: 0.5558\n",
      "Epoch 697/1000\n",
      "59/59 [==============================] - 0s 915us/step - loss: 0.5558 - val_loss: 0.5558\n",
      "Epoch 698/1000\n",
      "59/59 [==============================] - 0s 695us/step - loss: 0.5558 - val_loss: 0.5558\n",
      "Epoch 699/1000\n",
      "59/59 [==============================] - 0s 712us/step - loss: 0.5558 - val_loss: 0.5558\n",
      "Epoch 700/1000\n",
      "59/59 [==============================] - 0s 644us/step - loss: 0.5558 - val_loss: 0.5558\n",
      "Epoch 701/1000\n",
      "59/59 [==============================] - 0s 729us/step - loss: 0.5558 - val_loss: 0.5557\n",
      "Epoch 702/1000\n",
      "59/59 [==============================] - 0s 695us/step - loss: 0.5558 - val_loss: 0.5557\n",
      "Epoch 703/1000\n",
      "59/59 [==============================] - 0s 848us/step - loss: 0.5557 - val_loss: 0.5557\n",
      "Epoch 704/1000\n",
      "59/59 [==============================] - 0s 831us/step - loss: 0.5557 - val_loss: 0.5557\n",
      "Epoch 705/1000\n",
      "59/59 [==============================] - 0s 627us/step - loss: 0.5557 - val_loss: 0.5557\n",
      "Epoch 706/1000\n",
      "59/59 [==============================] - 0s 780us/step - loss: 0.5557 - val_loss: 0.5557\n",
      "Epoch 707/1000\n",
      "59/59 [==============================] - 0s 661us/step - loss: 0.5557 - val_loss: 0.5557\n",
      "Epoch 708/1000\n",
      "59/59 [==============================] - 0s 780us/step - loss: 0.5557 - val_loss: 0.5556\n",
      "Epoch 709/1000\n",
      "59/59 [==============================] - 0s 644us/step - loss: 0.5557 - val_loss: 0.5556\n",
      "Epoch 710/1000\n",
      "59/59 [==============================] - 0s 746us/step - loss: 0.5556 - val_loss: 0.5556\n",
      "Epoch 711/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59/59 [==============================] - 0s 661us/step - loss: 0.5556 - val_loss: 0.5556\n",
      "Epoch 712/1000\n",
      "59/59 [==============================] - 0s 780us/step - loss: 0.5556 - val_loss: 0.5556\n",
      "Epoch 713/1000\n",
      "59/59 [==============================] - 0s 610us/step - loss: 0.5556 - val_loss: 0.5556\n",
      "Epoch 714/1000\n",
      "59/59 [==============================] - 0s 729us/step - loss: 0.5556 - val_loss: 0.5556\n",
      "Epoch 715/1000\n",
      "59/59 [==============================] - 0s 780us/step - loss: 0.5556 - val_loss: 0.5555\n",
      "Epoch 716/1000\n",
      "59/59 [==============================] - 0s 814us/step - loss: 0.5555 - val_loss: 0.5555\n",
      "Epoch 717/1000\n",
      "59/59 [==============================] - 0s 780us/step - loss: 0.5555 - val_loss: 0.5555\n",
      "Epoch 718/1000\n",
      "59/59 [==============================] - 0s 797us/step - loss: 0.5555 - val_loss: 0.5555\n",
      "Epoch 719/1000\n",
      "59/59 [==============================] - 0s 831us/step - loss: 0.5555 - val_loss: 0.5555\n",
      "Epoch 720/1000\n",
      "59/59 [==============================] - 0s 797us/step - loss: 0.5555 - val_loss: 0.5555\n",
      "Epoch 721/1000\n",
      "59/59 [==============================] - 0s 864us/step - loss: 0.5555 - val_loss: 0.5554\n",
      "Epoch 722/1000\n",
      "59/59 [==============================] - 0s 881us/step - loss: 0.5555 - val_loss: 0.5554\n",
      "Epoch 723/1000\n",
      "59/59 [==============================] - 0s 848us/step - loss: 0.5554 - val_loss: 0.5554\n",
      "Epoch 724/1000\n",
      "59/59 [==============================] - 0s 746us/step - loss: 0.5554 - val_loss: 0.5554\n",
      "Epoch 725/1000\n",
      "59/59 [==============================] - 0s 898us/step - loss: 0.5554 - val_loss: 0.5554\n",
      "Epoch 726/1000\n",
      "59/59 [==============================] - 0s 797us/step - loss: 0.5554 - val_loss: 0.5554\n",
      "Epoch 727/1000\n",
      "59/59 [==============================] - 0s 644us/step - loss: 0.5554 - val_loss: 0.5554\n",
      "Epoch 728/1000\n",
      "59/59 [==============================] - 0s 881us/step - loss: 0.5554 - val_loss: 0.5553\n",
      "Epoch 729/1000\n",
      "59/59 [==============================] - 0s 746us/step - loss: 0.5553 - val_loss: 0.5553\n",
      "Epoch 730/1000\n",
      "59/59 [==============================] - 0s 712us/step - loss: 0.5553 - val_loss: 0.5553\n",
      "Epoch 731/1000\n",
      "59/59 [==============================] - 0s 678us/step - loss: 0.5553 - val_loss: 0.5553\n",
      "Epoch 732/1000\n",
      "59/59 [==============================] - 0s 864us/step - loss: 0.5553 - val_loss: 0.5553\n",
      "Epoch 733/1000\n",
      "59/59 [==============================] - 0s 881us/step - loss: 0.5553 - val_loss: 0.5553\n",
      "Epoch 734/1000\n",
      "59/59 [==============================] - 0s 848us/step - loss: 0.5553 - val_loss: 0.5552\n",
      "Epoch 735/1000\n",
      "59/59 [==============================] - 0s 932us/step - loss: 0.5553 - val_loss: 0.5552\n",
      "Epoch 736/1000\n",
      "59/59 [==============================] - 0s 864us/step - loss: 0.5552 - val_loss: 0.5552\n",
      "Epoch 737/1000\n",
      "59/59 [==============================] - 0s 831us/step - loss: 0.5552 - val_loss: 0.5552\n",
      "Epoch 738/1000\n",
      "59/59 [==============================] - 0s 848us/step - loss: 0.5552 - val_loss: 0.5552\n",
      "Epoch 739/1000\n",
      "59/59 [==============================] - 0s 678us/step - loss: 0.5552 - val_loss: 0.5552\n",
      "Epoch 740/1000\n",
      "59/59 [==============================] - 0s 915us/step - loss: 0.5552 - val_loss: 0.5552\n",
      "Epoch 741/1000\n",
      "59/59 [==============================] - 0s 729us/step - loss: 0.5552 - val_loss: 0.5551\n",
      "Epoch 742/1000\n",
      "59/59 [==============================] - 0s 797us/step - loss: 0.5551 - val_loss: 0.5551\n",
      "Epoch 743/1000\n",
      "59/59 [==============================] - 0s 831us/step - loss: 0.5551 - val_loss: 0.5551\n",
      "Epoch 744/1000\n",
      "59/59 [==============================] - 0s 797us/step - loss: 0.5551 - val_loss: 0.5551\n",
      "Epoch 745/1000\n",
      "59/59 [==============================] - 0s 797us/step - loss: 0.5551 - val_loss: 0.5551\n",
      "Epoch 746/1000\n",
      "59/59 [==============================] - 0s 712us/step - loss: 0.5551 - val_loss: 0.5551\n",
      "Epoch 747/1000\n",
      "59/59 [==============================] - 0s 814us/step - loss: 0.5551 - val_loss: 0.5550\n",
      "Epoch 748/1000\n",
      "59/59 [==============================] - 0s 864us/step - loss: 0.5551 - val_loss: 0.5550\n",
      "Epoch 749/1000\n",
      "59/59 [==============================] - 0s 814us/step - loss: 0.5550 - val_loss: 0.5550\n",
      "Epoch 750/1000\n",
      "59/59 [==============================] - 0s 763us/step - loss: 0.5550 - val_loss: 0.5550\n",
      "Epoch 751/1000\n",
      "59/59 [==============================] - 0s 661us/step - loss: 0.5550 - val_loss: 0.5550\n",
      "Epoch 752/1000\n",
      "59/59 [==============================] - 0s 695us/step - loss: 0.5550 - val_loss: 0.5550\n",
      "Epoch 753/1000\n",
      "59/59 [==============================] - 0s 763us/step - loss: 0.5550 - val_loss: 0.5550\n",
      "Epoch 754/1000\n",
      "59/59 [==============================] - 0s 814us/step - loss: 0.5550 - val_loss: 0.5549\n",
      "Epoch 755/1000\n",
      "59/59 [==============================] - 0s 746us/step - loss: 0.5549 - val_loss: 0.5549\n",
      "Epoch 756/1000\n",
      "59/59 [==============================] - 0s 797us/step - loss: 0.5549 - val_loss: 0.5549\n",
      "Epoch 757/1000\n",
      "59/59 [==============================] - 0s 797us/step - loss: 0.5549 - val_loss: 0.5549\n",
      "Epoch 758/1000\n",
      "59/59 [==============================] - 0s 712us/step - loss: 0.5549 - val_loss: 0.5549\n",
      "Epoch 759/1000\n",
      "59/59 [==============================] - 0s 881us/step - loss: 0.5549 - val_loss: 0.5549\n",
      "Epoch 760/1000\n",
      "59/59 [==============================] - 0s 814us/step - loss: 0.5549 - val_loss: 0.5548\n",
      "Epoch 761/1000\n",
      "59/59 [==============================] - 0s 661us/step - loss: 0.5549 - val_loss: 0.5548\n",
      "Epoch 762/1000\n",
      "59/59 [==============================] - 0s 797us/step - loss: 0.5548 - val_loss: 0.5548\n",
      "Epoch 763/1000\n",
      "59/59 [==============================] - 0s 746us/step - loss: 0.5548 - val_loss: 0.5548\n",
      "Epoch 764/1000\n",
      "59/59 [==============================] - 0s 712us/step - loss: 0.5548 - val_loss: 0.5548\n",
      "Epoch 765/1000\n",
      "59/59 [==============================] - 0s 627us/step - loss: 0.5548 - val_loss: 0.5548\n",
      "Epoch 766/1000\n",
      "59/59 [==============================] - 0s 746us/step - loss: 0.5548 - val_loss: 0.5547\n",
      "Epoch 767/1000\n",
      "59/59 [==============================] - 0s 661us/step - loss: 0.5548 - val_loss: 0.5547\n",
      "Epoch 768/1000\n",
      "59/59 [==============================] - 0s 780us/step - loss: 0.5547 - val_loss: 0.5547\n",
      "Epoch 769/1000\n",
      "59/59 [==============================] - 0s 644us/step - loss: 0.5547 - val_loss: 0.5547\n",
      "Epoch 770/1000\n",
      "59/59 [==============================] - 0s 797us/step - loss: 0.5547 - val_loss: 0.5547\n",
      "Epoch 771/1000\n",
      "59/59 [==============================] - 0s 848us/step - loss: 0.5547 - val_loss: 0.5547\n",
      "Epoch 772/1000\n",
      "59/59 [==============================] - 0s 746us/step - loss: 0.5547 - val_loss: 0.5547\n",
      "Epoch 773/1000\n",
      "59/59 [==============================] - 0s 678us/step - loss: 0.5547 - val_loss: 0.5546\n",
      "Epoch 774/1000\n",
      "59/59 [==============================] - 0s 864us/step - loss: 0.5546 - val_loss: 0.5546\n",
      "Epoch 775/1000\n",
      "59/59 [==============================] - 0s 746us/step - loss: 0.5546 - val_loss: 0.5546\n",
      "Epoch 776/1000\n",
      "59/59 [==============================] - 0s 695us/step - loss: 0.5546 - val_loss: 0.5546\n",
      "Epoch 777/1000\n",
      "59/59 [==============================] - 0s 898us/step - loss: 0.5546 - val_loss: 0.5546\n",
      "Epoch 778/1000\n",
      "59/59 [==============================] - 0s 729us/step - loss: 0.5546 - val_loss: 0.5546\n",
      "Epoch 779/1000\n",
      "59/59 [==============================] - 0s 780us/step - loss: 0.5546 - val_loss: 0.5545\n",
      "Epoch 780/1000\n",
      "59/59 [==============================] - 0s 712us/step - loss: 0.5546 - val_loss: 0.5545\n",
      "Epoch 781/1000\n",
      "59/59 [==============================] - 0s 881us/step - loss: 0.5545 - val_loss: 0.5545\n",
      "Epoch 782/1000\n",
      "59/59 [==============================] - 0s 712us/step - loss: 0.5545 - val_loss: 0.5545\n",
      "Epoch 783/1000\n",
      "59/59 [==============================] - 0s 797us/step - loss: 0.5545 - val_loss: 0.5545\n",
      "Epoch 784/1000\n",
      "59/59 [==============================] - 0s 729us/step - loss: 0.5545 - val_loss: 0.5545\n",
      "Epoch 785/1000\n",
      "59/59 [==============================] - 0s 763us/step - loss: 0.5545 - val_loss: 0.5545\n",
      "Epoch 786/1000\n",
      "59/59 [==============================] - 0s 627us/step - loss: 0.5545 - val_loss: 0.5544\n",
      "Epoch 787/1000\n",
      "59/59 [==============================] - 0s 797us/step - loss: 0.5544 - val_loss: 0.5544\n",
      "Epoch 788/1000\n",
      "59/59 [==============================] - 0s 627us/step - loss: 0.5544 - val_loss: 0.5544\n",
      "Epoch 789/1000\n",
      "59/59 [==============================] - 0s 763us/step - loss: 0.5544 - val_loss: 0.5544\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 790/1000\n",
      "59/59 [==============================] - 0s 712us/step - loss: 0.5544 - val_loss: 0.5544\n",
      "Epoch 791/1000\n",
      "59/59 [==============================] - 0s 763us/step - loss: 0.5544 - val_loss: 0.5544\n",
      "Epoch 792/1000\n",
      "59/59 [==============================] - 0s 627us/step - loss: 0.5544 - val_loss: 0.5543\n",
      "Epoch 793/1000\n",
      "59/59 [==============================] - 0s 881us/step - loss: 0.5544 - val_loss: 0.5543\n",
      "Epoch 794/1000\n",
      "59/59 [==============================] - 0s 949us/step - loss: 0.5543 - val_loss: 0.5543\n",
      "Epoch 795/1000\n",
      "59/59 [==============================] - 0s 831us/step - loss: 0.5543 - val_loss: 0.5543\n",
      "Epoch 796/1000\n",
      "59/59 [==============================] - 0s 881us/step - loss: 0.5543 - val_loss: 0.5543\n",
      "Epoch 797/1000\n",
      "59/59 [==============================] - 0s 898us/step - loss: 0.5543 - val_loss: 0.5543\n",
      "Epoch 798/1000\n",
      "59/59 [==============================] - 0s 949us/step - loss: 0.5543 - val_loss: 0.5543\n",
      "Epoch 799/1000\n",
      "59/59 [==============================] - 0s 881us/step - loss: 0.5543 - val_loss: 0.5542\n",
      "Epoch 800/1000\n",
      "59/59 [==============================] - 0s 780us/step - loss: 0.5542 - val_loss: 0.5542\n",
      "Epoch 801/1000\n",
      "59/59 [==============================] - 0s 848us/step - loss: 0.5542 - val_loss: 0.5542\n",
      "Epoch 802/1000\n",
      "59/59 [==============================] - 0s 898us/step - loss: 0.5542 - val_loss: 0.5542\n",
      "Epoch 803/1000\n",
      "59/59 [==============================] - 0s 814us/step - loss: 0.5542 - val_loss: 0.5542\n",
      "Epoch 804/1000\n",
      "59/59 [==============================] - 0s 932us/step - loss: 0.5542 - val_loss: 0.5542\n",
      "Epoch 805/1000\n",
      "59/59 [==============================] - 0s 949us/step - loss: 0.5542 - val_loss: 0.5541\n",
      "Epoch 806/1000\n",
      "59/59 [==============================] - 0s 814us/step - loss: 0.5542 - val_loss: 0.5541\n",
      "Epoch 807/1000\n",
      "59/59 [==============================] - 0s 780us/step - loss: 0.5541 - val_loss: 0.5541\n",
      "Epoch 808/1000\n",
      "59/59 [==============================] - 0s 746us/step - loss: 0.5541 - val_loss: 0.5541\n",
      "Epoch 809/1000\n",
      "59/59 [==============================] - 0s 729us/step - loss: 0.5541 - val_loss: 0.5541\n",
      "Epoch 810/1000\n",
      "59/59 [==============================] - 0s 780us/step - loss: 0.5541 - val_loss: 0.5541\n",
      "Epoch 811/1000\n",
      "59/59 [==============================] - 0s 712us/step - loss: 0.5541 - val_loss: 0.5541\n",
      "Epoch 812/1000\n",
      "59/59 [==============================] - 0s 831us/step - loss: 0.5541 - val_loss: 0.5540\n",
      "Epoch 813/1000\n",
      "59/59 [==============================] - 0s 780us/step - loss: 0.5540 - val_loss: 0.5540\n",
      "Epoch 814/1000\n",
      "59/59 [==============================] - 0s 864us/step - loss: 0.5540 - val_loss: 0.5540\n",
      "Epoch 815/1000\n",
      "59/59 [==============================] - 0s 898us/step - loss: 0.5540 - val_loss: 0.5540\n",
      "Epoch 816/1000\n",
      "59/59 [==============================] - 0s 797us/step - loss: 0.5540 - val_loss: 0.5540\n",
      "Epoch 817/1000\n",
      "59/59 [==============================] - 0s 780us/step - loss: 0.5540 - val_loss: 0.5540\n",
      "Epoch 818/1000\n",
      "59/59 [==============================] - 0s 712us/step - loss: 0.5540 - val_loss: 0.5539\n",
      "Epoch 819/1000\n",
      "59/59 [==============================] - 0s 780us/step - loss: 0.5539 - val_loss: 0.5539\n",
      "Epoch 820/1000\n",
      "59/59 [==============================] - 0s 864us/step - loss: 0.5539 - val_loss: 0.5539\n",
      "Epoch 821/1000\n",
      "59/59 [==============================] - 0s 729us/step - loss: 0.5539 - val_loss: 0.5539\n",
      "Epoch 822/1000\n",
      "59/59 [==============================] - 0s 848us/step - loss: 0.5539 - val_loss: 0.5539\n",
      "Epoch 823/1000\n",
      "59/59 [==============================] - 0s 695us/step - loss: 0.5539 - val_loss: 0.5539\n",
      "Epoch 824/1000\n",
      "59/59 [==============================] - 0s 678us/step - loss: 0.5539 - val_loss: 0.5539\n",
      "Epoch 825/1000\n",
      "59/59 [==============================] - 0s 915us/step - loss: 0.5539 - val_loss: 0.5538\n",
      "Epoch 826/1000\n",
      "59/59 [==============================] - 0s 746us/step - loss: 0.5539 - val_loss: 0.5538\n",
      "Epoch 827/1000\n",
      "59/59 [==============================] - 0s 712us/step - loss: 0.5538 - val_loss: 0.5538\n",
      "Epoch 828/1000\n",
      "59/59 [==============================] - 0s 831us/step - loss: 0.5538 - val_loss: 0.5538\n",
      "Epoch 829/1000\n",
      "59/59 [==============================] - 0s 848us/step - loss: 0.5538 - val_loss: 0.5538\n",
      "Epoch 830/1000\n",
      "59/59 [==============================] - 0s 729us/step - loss: 0.5538 - val_loss: 0.5538\n",
      "Epoch 831/1000\n",
      "59/59 [==============================] - 0s 729us/step - loss: 0.5538 - val_loss: 0.5537\n",
      "Epoch 832/1000\n",
      "59/59 [==============================] - 0s 831us/step - loss: 0.5537 - val_loss: 0.5537\n",
      "Epoch 833/1000\n",
      "59/59 [==============================] - 0s 746us/step - loss: 0.5537 - val_loss: 0.5537\n",
      "Epoch 834/1000\n",
      "59/59 [==============================] - 0s 729us/step - loss: 0.5537 - val_loss: 0.5537\n",
      "Epoch 835/1000\n",
      "59/59 [==============================] - 0s 848us/step - loss: 0.5537 - val_loss: 0.5537\n",
      "Epoch 836/1000\n",
      "59/59 [==============================] - 0s 763us/step - loss: 0.5537 - val_loss: 0.5537\n",
      "Epoch 837/1000\n",
      "59/59 [==============================] - 0s 763us/step - loss: 0.5537 - val_loss: 0.5537\n",
      "Epoch 838/1000\n",
      "59/59 [==============================] - 0s 797us/step - loss: 0.5537 - val_loss: 0.5536\n",
      "Epoch 839/1000\n",
      "59/59 [==============================] - 0s 797us/step - loss: 0.5536 - val_loss: 0.5536\n",
      "Epoch 840/1000\n",
      "59/59 [==============================] - 0s 763us/step - loss: 0.5536 - val_loss: 0.5536\n",
      "Epoch 841/1000\n",
      "59/59 [==============================] - 0s 729us/step - loss: 0.5536 - val_loss: 0.5536\n",
      "Epoch 842/1000\n",
      "59/59 [==============================] - 0s 797us/step - loss: 0.5536 - val_loss: 0.5536\n",
      "Epoch 843/1000\n",
      "59/59 [==============================] - 0s 678us/step - loss: 0.5536 - val_loss: 0.5536\n",
      "Epoch 844/1000\n",
      "59/59 [==============================] - 0s 915us/step - loss: 0.5536 - val_loss: 0.5535\n",
      "Epoch 845/1000\n",
      "59/59 [==============================] - 0s 881us/step - loss: 0.5536 - val_loss: 0.5535\n",
      "Epoch 846/1000\n",
      "59/59 [==============================] - 0s 661us/step - loss: 0.5535 - val_loss: 0.5535\n",
      "Epoch 847/1000\n",
      "59/59 [==============================] - 0s 848us/step - loss: 0.5535 - val_loss: 0.5535\n",
      "Epoch 848/1000\n",
      "59/59 [==============================] - 0s 661us/step - loss: 0.5535 - val_loss: 0.5535\n",
      "Epoch 849/1000\n",
      "59/59 [==============================] - 0s 695us/step - loss: 0.5535 - val_loss: 0.5535\n",
      "Epoch 850/1000\n",
      "59/59 [==============================] - 0s 797us/step - loss: 0.5535 - val_loss: 0.5535\n",
      "Epoch 851/1000\n",
      "59/59 [==============================] - 0s 695us/step - loss: 0.5535 - val_loss: 0.5534\n",
      "Epoch 852/1000\n",
      "59/59 [==============================] - 0s 695us/step - loss: 0.5535 - val_loss: 0.5534\n",
      "Epoch 853/1000\n",
      "59/59 [==============================] - 0s 797us/step - loss: 0.5534 - val_loss: 0.5534\n",
      "Epoch 854/1000\n",
      "59/59 [==============================] - 0s 695us/step - loss: 0.5534 - val_loss: 0.5534\n",
      "Epoch 855/1000\n",
      "59/59 [==============================] - 0s 848us/step - loss: 0.5534 - val_loss: 0.5534\n",
      "Epoch 856/1000\n",
      "59/59 [==============================] - 0s 729us/step - loss: 0.5534 - val_loss: 0.5534\n",
      "Epoch 857/1000\n",
      "59/59 [==============================] - 0s 678us/step - loss: 0.5534 - val_loss: 0.5533\n",
      "Epoch 858/1000\n",
      "59/59 [==============================] - 0s 712us/step - loss: 0.5534 - val_loss: 0.5533\n",
      "Epoch 859/1000\n",
      "59/59 [==============================] - 0s 695us/step - loss: 0.5533 - val_loss: 0.5533\n",
      "Epoch 860/1000\n",
      "59/59 [==============================] - 0s 695us/step - loss: 0.5533 - val_loss: 0.5533\n",
      "Epoch 861/1000\n",
      "59/59 [==============================] - 0s 627us/step - loss: 0.5533 - val_loss: 0.5533\n",
      "Epoch 862/1000\n",
      "59/59 [==============================] - 0s 712us/step - loss: 0.5533 - val_loss: 0.5533\n",
      "Epoch 863/1000\n",
      "59/59 [==============================] - 0s 678us/step - loss: 0.5533 - val_loss: 0.5533\n",
      "Epoch 864/1000\n",
      "59/59 [==============================] - 0s 695us/step - loss: 0.5533 - val_loss: 0.5532\n",
      "Epoch 865/1000\n",
      "59/59 [==============================] - 0s 797us/step - loss: 0.5532 - val_loss: 0.5532\n",
      "Epoch 866/1000\n",
      "59/59 [==============================] - 0s 610us/step - loss: 0.5532 - val_loss: 0.5532\n",
      "Epoch 867/1000\n",
      "59/59 [==============================] - 0s 780us/step - loss: 0.5532 - val_loss: 0.5532\n",
      "Epoch 868/1000\n",
      "59/59 [==============================] - 0s 644us/step - loss: 0.5532 - val_loss: 0.5532\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 869/1000\n",
      "59/59 [==============================] - 0s 712us/step - loss: 0.5532 - val_loss: 0.5532\n",
      "Epoch 870/1000\n",
      "59/59 [==============================] - 0s 627us/step - loss: 0.5532 - val_loss: 0.5532\n",
      "Epoch 871/1000\n",
      "59/59 [==============================] - 0s 881us/step - loss: 0.5532 - val_loss: 0.5531\n",
      "Epoch 872/1000\n",
      "59/59 [==============================] - 0s 797us/step - loss: 0.5531 - val_loss: 0.5531\n",
      "Epoch 873/1000\n",
      "59/59 [==============================] - 0s 898us/step - loss: 0.5531 - val_loss: 0.5531\n",
      "Epoch 874/1000\n",
      "59/59 [==============================] - 0s 949us/step - loss: 0.5531 - val_loss: 0.5531\n",
      "Epoch 875/1000\n",
      "59/59 [==============================] - 0s 966us/step - loss: 0.5531 - val_loss: 0.5531\n",
      "Epoch 876/1000\n",
      "59/59 [==============================] - 0s 814us/step - loss: 0.5531 - val_loss: 0.5531\n",
      "Epoch 877/1000\n",
      "59/59 [==============================] - 0s 763us/step - loss: 0.5531 - val_loss: 0.5530\n",
      "Epoch 878/1000\n",
      "59/59 [==============================] - 0s 932us/step - loss: 0.5531 - val_loss: 0.5530\n",
      "Epoch 879/1000\n",
      "59/59 [==============================] - 0s 898us/step - loss: 0.5530 - val_loss: 0.5530\n",
      "Epoch 880/1000\n",
      "59/59 [==============================] - 0s 695us/step - loss: 0.5530 - val_loss: 0.5530\n",
      "Epoch 881/1000\n",
      "59/59 [==============================] - 0s 831us/step - loss: 0.5530 - val_loss: 0.5530\n",
      "Epoch 882/1000\n",
      "59/59 [==============================] - 0s 898us/step - loss: 0.5530 - val_loss: 0.5530\n",
      "Epoch 883/1000\n",
      "59/59 [==============================] - 0s 780us/step - loss: 0.5530 - val_loss: 0.5530\n",
      "Epoch 884/1000\n",
      "59/59 [==============================] - 0s 695us/step - loss: 0.5530 - val_loss: 0.5529\n",
      "Epoch 885/1000\n",
      "59/59 [==============================] - 0s 797us/step - loss: 0.5529 - val_loss: 0.5529\n",
      "Epoch 886/1000\n",
      "59/59 [==============================] - 0s 729us/step - loss: 0.5529 - val_loss: 0.5529\n",
      "Epoch 887/1000\n",
      "59/59 [==============================] - 0s 864us/step - loss: 0.5529 - val_loss: 0.5529\n",
      "Epoch 888/1000\n",
      "59/59 [==============================] - 0s 780us/step - loss: 0.5529 - val_loss: 0.5529\n",
      "Epoch 889/1000\n",
      "59/59 [==============================] - 0s 864us/step - loss: 0.5529 - val_loss: 0.5529\n",
      "Epoch 890/1000\n",
      "59/59 [==============================] - 0s 932us/step - loss: 0.5529 - val_loss: 0.5529\n",
      "Epoch 891/1000\n",
      "59/59 [==============================] - 0s 848us/step - loss: 0.5529 - val_loss: 0.5528\n",
      "Epoch 892/1000\n",
      "59/59 [==============================] - 0s 729us/step - loss: 0.5528 - val_loss: 0.5528\n",
      "Epoch 893/1000\n",
      "59/59 [==============================] - 0s 949us/step - loss: 0.5528 - val_loss: 0.5528\n",
      "Epoch 894/1000\n",
      "59/59 [==============================] - 0s 763us/step - loss: 0.5528 - val_loss: 0.5528\n",
      "Epoch 895/1000\n",
      "59/59 [==============================] - 0s 746us/step - loss: 0.5528 - val_loss: 0.5528\n",
      "Epoch 896/1000\n",
      "59/59 [==============================] - 0s 746us/step - loss: 0.5528 - val_loss: 0.5528\n",
      "Epoch 897/1000\n",
      "59/59 [==============================] - 0s 898us/step - loss: 0.5528 - val_loss: 0.5528\n",
      "Epoch 898/1000\n",
      "59/59 [==============================] - 0s 848us/step - loss: 0.5528 - val_loss: 0.5527\n",
      "Epoch 899/1000\n",
      "59/59 [==============================] - 0s 712us/step - loss: 0.5527 - val_loss: 0.5527\n",
      "Epoch 900/1000\n",
      "59/59 [==============================] - 0s 814us/step - loss: 0.5527 - val_loss: 0.5527\n",
      "Epoch 901/1000\n",
      "59/59 [==============================] - 0s 814us/step - loss: 0.5527 - val_loss: 0.5527\n",
      "Epoch 902/1000\n",
      "59/59 [==============================] - 0s 695us/step - loss: 0.5527 - val_loss: 0.5527\n",
      "Epoch 903/1000\n",
      "59/59 [==============================] - 0s 848us/step - loss: 0.5527 - val_loss: 0.5527\n",
      "Epoch 904/1000\n",
      "59/59 [==============================] - 0s 814us/step - loss: 0.5527 - val_loss: 0.5527\n",
      "Epoch 905/1000\n",
      "59/59 [==============================] - 0s 814us/step - loss: 0.5527 - val_loss: 0.5526\n",
      "Epoch 906/1000\n",
      "59/59 [==============================] - 0s 763us/step - loss: 0.5526 - val_loss: 0.5526\n",
      "Epoch 907/1000\n",
      "59/59 [==============================] - 0s 797us/step - loss: 0.5526 - val_loss: 0.5526\n",
      "Epoch 908/1000\n",
      "59/59 [==============================] - 0s 729us/step - loss: 0.5526 - val_loss: 0.5526\n",
      "Epoch 909/1000\n",
      "59/59 [==============================] - 0s 797us/step - loss: 0.5526 - val_loss: 0.5526\n",
      "Epoch 910/1000\n",
      "59/59 [==============================] - 0s 661us/step - loss: 0.5526 - val_loss: 0.5526\n",
      "Epoch 911/1000\n",
      "59/59 [==============================] - 0s 848us/step - loss: 0.5526 - val_loss: 0.5526\n",
      "Epoch 912/1000\n",
      "59/59 [==============================] - 0s 780us/step - loss: 0.5526 - val_loss: 0.5525\n",
      "Epoch 913/1000\n",
      "59/59 [==============================] - 0s 729us/step - loss: 0.5526 - val_loss: 0.5525\n",
      "Epoch 914/1000\n",
      "59/59 [==============================] - 0s 797us/step - loss: 0.5525 - val_loss: 0.5525\n",
      "Epoch 915/1000\n",
      "59/59 [==============================] - 0s 864us/step - loss: 0.5525 - val_loss: 0.5525\n",
      "Epoch 916/1000\n",
      "59/59 [==============================] - 0s 848us/step - loss: 0.5525 - val_loss: 0.5525\n",
      "Epoch 917/1000\n",
      "59/59 [==============================] - 0s 661us/step - loss: 0.5525 - val_loss: 0.5525\n",
      "Epoch 918/1000\n",
      "59/59 [==============================] - 0s 831us/step - loss: 0.5525 - val_loss: 0.5525\n",
      "Epoch 919/1000\n",
      "59/59 [==============================] - 0s 814us/step - loss: 0.5525 - val_loss: 0.5524\n",
      "Epoch 920/1000\n",
      "59/59 [==============================] - 0s 712us/step - loss: 0.5525 - val_loss: 0.5524\n",
      "Epoch 921/1000\n",
      "59/59 [==============================] - 0s 780us/step - loss: 0.5524 - val_loss: 0.5524\n",
      "Epoch 922/1000\n",
      "59/59 [==============================] - 0s 848us/step - loss: 0.5524 - val_loss: 0.5524\n",
      "Epoch 923/1000\n",
      "59/59 [==============================] - 0s 814us/step - loss: 0.5524 - val_loss: 0.5524\n",
      "Epoch 924/1000\n",
      "59/59 [==============================] - 0s 678us/step - loss: 0.5524 - val_loss: 0.5524\n",
      "Epoch 925/1000\n",
      "59/59 [==============================] - 0s 627us/step - loss: 0.5524 - val_loss: 0.5524\n",
      "Epoch 926/1000\n",
      "59/59 [==============================] - 0s 746us/step - loss: 0.5524 - val_loss: 0.5523\n",
      "Epoch 927/1000\n",
      "59/59 [==============================] - 0s 780us/step - loss: 0.5524 - val_loss: 0.5523\n",
      "Epoch 928/1000\n",
      "59/59 [==============================] - 0s 814us/step - loss: 0.5523 - val_loss: 0.5523\n",
      "Epoch 929/1000\n",
      "59/59 [==============================] - 0s 814us/step - loss: 0.5523 - val_loss: 0.5523\n",
      "Epoch 930/1000\n",
      "59/59 [==============================] - 0s 746us/step - loss: 0.5523 - val_loss: 0.5523\n",
      "Epoch 931/1000\n",
      "59/59 [==============================] - 0s 746us/step - loss: 0.5523 - val_loss: 0.5523\n",
      "Epoch 932/1000\n",
      "59/59 [==============================] - 0s 763us/step - loss: 0.5523 - val_loss: 0.5523\n",
      "Epoch 933/1000\n",
      "59/59 [==============================] - 0s 695us/step - loss: 0.5523 - val_loss: 0.5523\n",
      "Epoch 934/1000\n",
      "59/59 [==============================] - 0s 780us/step - loss: 0.5523 - val_loss: 0.5522\n",
      "Epoch 935/1000\n",
      "59/59 [==============================] - 0s 678us/step - loss: 0.5522 - val_loss: 0.5522\n",
      "Epoch 936/1000\n",
      "59/59 [==============================] - 0s 661us/step - loss: 0.5522 - val_loss: 0.5522\n",
      "Epoch 937/1000\n",
      "59/59 [==============================] - 0s 763us/step - loss: 0.5522 - val_loss: 0.5522\n",
      "Epoch 938/1000\n",
      "59/59 [==============================] - 0s 695us/step - loss: 0.5522 - val_loss: 0.5522\n",
      "Epoch 939/1000\n",
      "59/59 [==============================] - 0s 763us/step - loss: 0.5522 - val_loss: 0.5522\n",
      "Epoch 940/1000\n",
      "59/59 [==============================] - 0s 627us/step - loss: 0.5522 - val_loss: 0.5522\n",
      "Epoch 941/1000\n",
      "59/59 [==============================] - 0s 763us/step - loss: 0.5522 - val_loss: 0.5521\n",
      "Epoch 942/1000\n",
      "59/59 [==============================] - 0s 610us/step - loss: 0.5522 - val_loss: 0.5521\n",
      "Epoch 943/1000\n",
      "59/59 [==============================] - 0s 898us/step - loss: 0.5521 - val_loss: 0.5521\n",
      "Epoch 944/1000\n",
      "59/59 [==============================] - 0s 797us/step - loss: 0.5521 - val_loss: 0.5521\n",
      "Epoch 945/1000\n",
      "59/59 [==============================] - 0s 678us/step - loss: 0.5521 - val_loss: 0.5521\n",
      "Epoch 946/1000\n",
      "59/59 [==============================] - 0s 949us/step - loss: 0.5521 - val_loss: 0.5521\n",
      "Epoch 947/1000\n",
      "59/59 [==============================] - 0s 661us/step - loss: 0.5521 - val_loss: 0.5521\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 948/1000\n",
      "59/59 [==============================] - 0s 763us/step - loss: 0.5521 - val_loss: 0.5521\n",
      "Epoch 949/1000\n",
      "59/59 [==============================] - 0s 746us/step - loss: 0.5521 - val_loss: 0.5520\n",
      "Epoch 950/1000\n",
      "59/59 [==============================] - 0s 763us/step - loss: 0.5521 - val_loss: 0.5520\n",
      "Epoch 951/1000\n",
      "59/59 [==============================] - 0s 610us/step - loss: 0.5520 - val_loss: 0.5520\n",
      "Epoch 952/1000\n",
      "59/59 [==============================] - 0s 814us/step - loss: 0.5520 - val_loss: 0.5520\n",
      "Epoch 953/1000\n",
      "59/59 [==============================] - 0s 915us/step - loss: 0.5520 - val_loss: 0.5520\n",
      "Epoch 954/1000\n",
      "59/59 [==============================] - 0s 814us/step - loss: 0.5520 - val_loss: 0.5520\n",
      "Epoch 955/1000\n",
      "59/59 [==============================] - 0s 915us/step - loss: 0.5520 - val_loss: 0.5520\n",
      "Epoch 956/1000\n",
      "59/59 [==============================] - 0s 814us/step - loss: 0.5520 - val_loss: 0.5519\n",
      "Epoch 957/1000\n",
      "59/59 [==============================] - 0s 881us/step - loss: 0.5520 - val_loss: 0.5519\n",
      "Epoch 958/1000\n",
      "59/59 [==============================] - 0s 831us/step - loss: 0.5519 - val_loss: 0.5519\n",
      "Epoch 959/1000\n",
      "59/59 [==============================] - 0s 881us/step - loss: 0.5519 - val_loss: 0.5519\n",
      "Epoch 960/1000\n",
      "59/59 [==============================] - 0s 780us/step - loss: 0.5519 - val_loss: 0.5519\n",
      "Epoch 961/1000\n",
      "59/59 [==============================] - 0s 610us/step - loss: 0.5519 - val_loss: 0.5519\n",
      "Epoch 962/1000\n",
      "59/59 [==============================] - 0s 831us/step - loss: 0.5519 - val_loss: 0.5519\n",
      "Epoch 963/1000\n",
      "59/59 [==============================] - 0s 848us/step - loss: 0.5519 - val_loss: 0.5519\n",
      "Epoch 964/1000\n",
      "59/59 [==============================] - 0s 864us/step - loss: 0.5519 - val_loss: 0.5518\n",
      "Epoch 965/1000\n",
      "59/59 [==============================] - 0s 864us/step - loss: 0.5519 - val_loss: 0.5518\n",
      "Epoch 966/1000\n",
      "59/59 [==============================] - 0s 848us/step - loss: 0.5519 - val_loss: 0.5518\n",
      "Epoch 967/1000\n",
      "59/59 [==============================] - 0s 848us/step - loss: 0.5518 - val_loss: 0.5518\n",
      "Epoch 968/1000\n",
      "59/59 [==============================] - 0s 814us/step - loss: 0.5518 - val_loss: 0.5518\n",
      "Epoch 969/1000\n",
      "59/59 [==============================] - 0s 678us/step - loss: 0.5518 - val_loss: 0.5518\n",
      "Epoch 970/1000\n",
      "59/59 [==============================] - 0s 712us/step - loss: 0.5518 - val_loss: 0.5518\n",
      "Epoch 971/1000\n",
      "59/59 [==============================] - 0s 864us/step - loss: 0.5518 - val_loss: 0.5518\n",
      "Epoch 972/1000\n",
      "59/59 [==============================] - 0s 831us/step - loss: 0.5518 - val_loss: 0.5517\n",
      "Epoch 973/1000\n",
      "59/59 [==============================] - 0s 864us/step - loss: 0.5518 - val_loss: 0.5517\n",
      "Epoch 974/1000\n",
      "59/59 [==============================] - 0s 848us/step - loss: 0.5517 - val_loss: 0.5517\n",
      "Epoch 975/1000\n",
      "59/59 [==============================] - 0s 763us/step - loss: 0.5517 - val_loss: 0.5517\n",
      "Epoch 976/1000\n",
      "59/59 [==============================] - 0s 746us/step - loss: 0.5517 - val_loss: 0.5517\n",
      "Epoch 977/1000\n",
      "59/59 [==============================] - 0s 763us/step - loss: 0.5517 - val_loss: 0.5517\n",
      "Epoch 978/1000\n",
      "59/59 [==============================] - 0s 695us/step - loss: 0.5517 - val_loss: 0.5517\n",
      "Epoch 979/1000\n",
      "59/59 [==============================] - 0s 797us/step - loss: 0.5517 - val_loss: 0.5517\n",
      "Epoch 980/1000\n",
      "59/59 [==============================] - 0s 763us/step - loss: 0.5517 - val_loss: 0.5516\n",
      "Epoch 981/1000\n",
      "59/59 [==============================] - 0s 678us/step - loss: 0.5517 - val_loss: 0.5516\n",
      "Epoch 982/1000\n",
      "59/59 [==============================] - 0s 729us/step - loss: 0.5516 - val_loss: 0.5516\n",
      "Epoch 983/1000\n",
      "59/59 [==============================] - 0s 881us/step - loss: 0.5516 - val_loss: 0.5516\n",
      "Epoch 984/1000\n",
      "59/59 [==============================] - 0s 797us/step - loss: 0.5516 - val_loss: 0.5516\n",
      "Epoch 985/1000\n",
      "59/59 [==============================] - 0s 814us/step - loss: 0.5516 - val_loss: 0.5516\n",
      "Epoch 986/1000\n",
      "59/59 [==============================] - 0s 763us/step - loss: 0.5516 - val_loss: 0.5516\n",
      "Epoch 987/1000\n",
      "59/59 [==============================] - 0s 712us/step - loss: 0.5516 - val_loss: 0.5516\n",
      "Epoch 988/1000\n",
      "59/59 [==============================] - 0s 797us/step - loss: 0.5516 - val_loss: 0.5516\n",
      "Epoch 989/1000\n",
      "59/59 [==============================] - 0s 695us/step - loss: 0.5516 - val_loss: 0.5515\n",
      "Epoch 990/1000\n",
      "59/59 [==============================] - 0s 729us/step - loss: 0.5515 - val_loss: 0.5515\n",
      "Epoch 991/1000\n",
      "59/59 [==============================] - 0s 831us/step - loss: 0.5515 - val_loss: 0.5515\n",
      "Epoch 992/1000\n",
      "59/59 [==============================] - 0s 712us/step - loss: 0.5515 - val_loss: 0.5515\n",
      "Epoch 993/1000\n",
      "59/59 [==============================] - 0s 780us/step - loss: 0.5515 - val_loss: 0.5515\n",
      "Epoch 994/1000\n",
      "59/59 [==============================] - 0s 915us/step - loss: 0.5515 - val_loss: 0.5515\n",
      "Epoch 995/1000\n",
      "59/59 [==============================] - ETA: 0s - loss: 0.551 - 0s 797us/step - loss: 0.5515 - val_loss: 0.5515\n",
      "Epoch 996/1000\n",
      "59/59 [==============================] - 0s 661us/step - loss: 0.5515 - val_loss: 0.5515\n",
      "Epoch 997/1000\n",
      "59/59 [==============================] - 0s 763us/step - loss: 0.5515 - val_loss: 0.5514\n",
      "Epoch 998/1000\n",
      "59/59 [==============================] - 0s 848us/step - loss: 0.5515 - val_loss: 0.5514\n",
      "Epoch 999/1000\n",
      "59/59 [==============================] - 0s 729us/step - loss: 0.5514 - val_loss: 0.5514\n",
      "Epoch 1000/1000\n",
      "59/59 [==============================] - 0s 729us/step - loss: 0.5514 - val_loss: 0.5514\n",
      "end\n"
     ]
    }
   ],
   "source": [
    "autoencoder.fit(x_train, x_train,\n",
    "                epochs=1000,\n",
    "                batch_size=32,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, x_test))\n",
    "\n",
    "print('end')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_json = model.to_json()\n",
    "# json_file = open(\"photos_model.json\", \"w\")\n",
    "# loaded_model_json = json_file.read()\n",
    "# json_file.close()\n",
    "# loaded_model = model_from_json(loaded_model_json)\n",
    "autoencoder.save_weights(\"photos_copy.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0000000e+00 3.9130912e+00 0.0000000e+00 1.8572196e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 4.0228403e-01 4.2380795e+00 2.0815015e+00 0.0000000e+00\n",
      " 0.0000000e+00 3.1584990e-01 2.7914956e+00 9.6533072e-01 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 2.0424151e+00 0.0000000e+00 0.0000000e+00\n",
      " 1.0275068e+00 5.2823985e-01 0.0000000e+00 7.8265829e+00 1.2930619e+00\n",
      " 6.0591623e-03 3.2437989e-01]\n",
      "[[0.0000000e+00 3.9130912e+00 0.0000000e+00 ... 1.2930619e+00\n",
      "  6.0591623e-03 3.2437989e-01]\n",
      " [2.9752233e+00 3.1366584e+00 0.0000000e+00 ... 1.0975564e+00\n",
      "  0.0000000e+00 5.2599607e+00]\n",
      " [3.7600586e+00 2.9813030e+00 0.0000000e+00 ... 1.3708086e+00\n",
      "  0.0000000e+00 5.9729328e+00]\n",
      " ...\n",
      " [3.5522988e+00 2.6382010e+00 0.0000000e+00 ... 1.3420084e+00\n",
      "  0.0000000e+00 5.7187958e+00]\n",
      " [1.5828104e+00 4.7130316e-01 0.0000000e+00 ... 3.5210886e+00\n",
      "  1.2789012e+01 0.0000000e+00]\n",
      " [1.5432047e+00 5.4852223e-01 0.0000000e+00 ... 3.5309701e+00\n",
      "  1.2602270e+01 0.0000000e+00]]\n",
      "end\n"
     ]
    }
   ],
   "source": [
    "# encode and decode some digits\n",
    "# note that we take them from the *test* set\n",
    "encoded_imgs = encoder.predict(x_test)\n",
    "\n",
    "decoded_imgs = decoder.predict(encoded_imgs)\n",
    "print(encoded_imgs[0])\n",
    "print(encoded_imgs)\n",
    "\n",
    "# mean = encoded_imgs.mean(axis=0)\n",
    "# std = encoded_imgs.std(axis=0)\n",
    "# encoded_imgs -= mean\n",
    "# encoded_imgs /= std\n",
    "# print(encoded_imgs[0])\n",
    "\n",
    "\n",
    "print('end')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Any\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:29: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(32, input_dim=32, activation=\"relu\", kernel_initializer=\"normal\")`\n",
      "C:\\Users\\Any\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:30: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(4, activation=\"softmax\", kernel_initializer=\"normal\")`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_15 (Dense)             (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 4)                 132       \n",
      "=================================================================\n",
      "Total params: 1,188\n",
      "Trainable params: 1,188\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Dense\n",
    "from keras.utils import np_utils\n",
    "\n",
    "# numpy.random.seed(59)\n",
    "\n",
    "# (X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# X_train = X_train.reshape(60000, 784)\n",
    "# X_test = X_test.reshape(10000, 784)\n",
    "\n",
    "# X_train = X_train.astype('float32')\n",
    "# X_test = X_test.astype('float32')\n",
    "# X_train /= 255\n",
    "# X_test /= 255\n",
    "\n",
    "# Y_train = np_utils.to_categorical(y_train, 4)\n",
    "# Y_test = np_utils.to_categorical(y_test, 4)\n",
    "\n",
    "X_train = encoded_imgs\n",
    "Y_train = np_utils.to_categorical(labels, 4)\n",
    "\n",
    "# print(X_train)\n",
    "# print(Y_train)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(32, input_dim=32, init=\"normal\", activation=\"relu\"))\n",
    "model.add(Dense(4, init=\"normal\", activation=\"softmax\"))\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"SGD\",  metrics=[\"accuracy\"])\n",
    "\n",
    "print(model.summary())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Any\\Anaconda3\\lib\\site-packages\\keras\\models.py:942: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "59/59 [==============================] - 1s 14ms/step - loss: 1.4083 - acc: 0.0000e+00\n",
      "Epoch 2/100\n",
      "59/59 [==============================] - 0s 356us/step - loss: 1.3905 - acc: 0.0000e+00\n",
      "Epoch 3/100\n",
      "59/59 [==============================] - 0s 220us/step - loss: 1.3723 - acc: 0.0000e+00\n",
      "Epoch 4/100\n",
      "59/59 [==============================] - 0s 407us/step - loss: 1.3550 - acc: 0.2203\n",
      "Epoch 5/100\n",
      "59/59 [==============================] - 0s 322us/step - loss: 1.3387 - acc: 0.5085\n",
      "Epoch 6/100\n",
      "59/59 [==============================] - 0s 322us/step - loss: 1.3209 - acc: 0.5085\n",
      "Epoch 7/100\n",
      "59/59 [==============================] - 0s 322us/step - loss: 1.3034 - acc: 0.5085\n",
      "Epoch 8/100\n",
      "59/59 [==============================] - 0s 305us/step - loss: 1.2859 - acc: 0.5085\n",
      "Epoch 9/100\n",
      "59/59 [==============================] - 0s 356us/step - loss: 1.2671 - acc: 0.5085\n",
      "Epoch 10/100\n",
      "59/59 [==============================] - 0s 542us/step - loss: 1.2486 - acc: 0.5254\n",
      "Epoch 11/100\n",
      "59/59 [==============================] - 0s 525us/step - loss: 1.2295 - acc: 0.5932\n",
      "Epoch 12/100\n",
      "59/59 [==============================] - 0s 305us/step - loss: 1.2100 - acc: 0.6271\n",
      "Epoch 13/100\n",
      "59/59 [==============================] - 0s 509us/step - loss: 1.1901 - acc: 0.6271\n",
      "Epoch 14/100\n",
      "59/59 [==============================] - 0s 424us/step - loss: 1.1679 - acc: 0.6949\n",
      "Epoch 15/100\n",
      "59/59 [==============================] - 0s 271us/step - loss: 1.1458 - acc: 0.7119\n",
      "Epoch 16/100\n",
      "59/59 [==============================] - 0s 288us/step - loss: 1.1235 - acc: 0.7458\n",
      "Epoch 17/100\n",
      "59/59 [==============================] - 0s 593us/step - loss: 1.1001 - acc: 0.7797\n",
      "Epoch 18/100\n",
      "59/59 [==============================] - 0s 356us/step - loss: 1.0773 - acc: 0.8136\n",
      "Epoch 19/100\n",
      "59/59 [==============================] - 0s 237us/step - loss: 1.0529 - acc: 0.8983\n",
      "Epoch 20/100\n",
      "59/59 [==============================] - 0s 271us/step - loss: 1.0282 - acc: 0.9322\n",
      "Epoch 21/100\n",
      "59/59 [==============================] - 0s 356us/step - loss: 1.0039 - acc: 0.9492\n",
      "Epoch 22/100\n",
      "59/59 [==============================] - 0s 390us/step - loss: 0.9799 - acc: 1.0000\n",
      "Epoch 23/100\n",
      "59/59 [==============================] - 0s 305us/step - loss: 0.9551 - acc: 1.0000\n",
      "Epoch 24/100\n",
      "59/59 [==============================] - 0s 271us/step - loss: 0.9311 - acc: 1.0000\n",
      "Epoch 25/100\n",
      "59/59 [==============================] - 0s 305us/step - loss: 0.9066 - acc: 1.0000\n",
      "Epoch 26/100\n",
      "59/59 [==============================] - 0s 220us/step - loss: 0.8832 - acc: 1.0000\n",
      "Epoch 27/100\n",
      "59/59 [==============================] - 0s 254us/step - loss: 0.8595 - acc: 1.0000\n",
      "Epoch 28/100\n",
      "59/59 [==============================] - 0s 424us/step - loss: 0.8361 - acc: 1.0000\n",
      "Epoch 29/100\n",
      "59/59 [==============================] - 0s 237us/step - loss: 0.8139 - acc: 1.0000\n",
      "Epoch 30/100\n",
      "59/59 [==============================] - 0s 237us/step - loss: 0.7910 - acc: 1.0000\n",
      "Epoch 31/100\n",
      "59/59 [==============================] - 0s 220us/step - loss: 0.7692 - acc: 1.0000\n",
      "Epoch 32/100\n",
      "59/59 [==============================] - 0s 254us/step - loss: 0.7481 - acc: 1.0000\n",
      "Epoch 33/100\n",
      "59/59 [==============================] - 0s 220us/step - loss: 0.7270 - acc: 1.0000\n",
      "Epoch 34/100\n",
      "59/59 [==============================] - 0s 271us/step - loss: 0.7069 - acc: 1.0000\n",
      "Epoch 35/100\n",
      "59/59 [==============================] - 0s 509us/step - loss: 0.6873 - acc: 1.0000\n",
      "Epoch 36/100\n",
      "59/59 [==============================] - 0s 271us/step - loss: 0.6683 - acc: 1.0000\n",
      "Epoch 37/100\n",
      "59/59 [==============================] - 0s 220us/step - loss: 0.6494 - acc: 1.0000\n",
      "Epoch 38/100\n",
      "59/59 [==============================] - 0s 288us/step - loss: 0.6318 - acc: 1.0000\n",
      "Epoch 39/100\n",
      "59/59 [==============================] - 0s 254us/step - loss: 0.6147 - acc: 1.0000\n",
      "Epoch 40/100\n",
      "59/59 [==============================] - 0s 254us/step - loss: 0.5968 - acc: 1.0000\n",
      "Epoch 41/100\n",
      "59/59 [==============================] - 0s 254us/step - loss: 0.5805 - acc: 1.0000\n",
      "Epoch 42/100\n",
      "59/59 [==============================] - 0s 305us/step - loss: 0.5648 - acc: 1.0000\n",
      "Epoch 43/100\n",
      "59/59 [==============================] - 0s 441us/step - loss: 0.5499 - acc: 1.0000\n",
      "Epoch 44/100\n",
      "59/59 [==============================] - 0s 492us/step - loss: 0.5348 - acc: 1.0000\n",
      "Epoch 45/100\n",
      "59/59 [==============================] - 0s 203us/step - loss: 0.5215 - acc: 1.0000\n",
      "Epoch 46/100\n",
      "59/59 [==============================] - 0s 237us/step - loss: 0.5069 - acc: 1.0000\n",
      "Epoch 47/100\n",
      "59/59 [==============================] - 0s 271us/step - loss: 0.4939 - acc: 1.0000\n",
      "Epoch 48/100\n",
      "59/59 [==============================] - 0s 305us/step - loss: 0.4810 - acc: 1.0000\n",
      "Epoch 49/100\n",
      "59/59 [==============================] - 0s 373us/step - loss: 0.4702 - acc: 1.0000\n",
      "Epoch 50/100\n",
      "59/59 [==============================] - 0s 356us/step - loss: 0.4585 - acc: 1.0000\n",
      "Epoch 51/100\n",
      "59/59 [==============================] - 0s 271us/step - loss: 0.4468 - acc: 1.0000\n",
      "Epoch 52/100\n",
      "59/59 [==============================] - 0s 271us/step - loss: 0.4352 - acc: 1.0000\n",
      "Epoch 53/100\n",
      "59/59 [==============================] - 0s 390us/step - loss: 0.4242 - acc: 1.0000\n",
      "Epoch 54/100\n",
      "59/59 [==============================] - 0s 373us/step - loss: 0.4140 - acc: 1.0000\n",
      "Epoch 55/100\n",
      "59/59 [==============================] - 0s 458us/step - loss: 0.4042 - acc: 1.0000\n",
      "Epoch 56/100\n",
      "59/59 [==============================] - 0s 339us/step - loss: 0.3945 - acc: 1.0000\n",
      "Epoch 57/100\n",
      "59/59 [==============================] - 0s 237us/step - loss: 0.3855 - acc: 1.0000\n",
      "Epoch 58/100\n",
      "59/59 [==============================] - 0s 356us/step - loss: 0.3765 - acc: 1.0000\n",
      "Epoch 59/100\n",
      "59/59 [==============================] - 0s 339us/step - loss: 0.3672 - acc: 1.0000\n",
      "Epoch 60/100\n",
      "59/59 [==============================] - 0s 305us/step - loss: 0.3597 - acc: 1.0000\n",
      "Epoch 61/100\n",
      "59/59 [==============================] - 0s 271us/step - loss: 0.3504 - acc: 1.0000\n",
      "Epoch 62/100\n",
      "59/59 [==============================] - 0s 220us/step - loss: 0.3425 - acc: 1.0000\n",
      "Epoch 63/100\n",
      "59/59 [==============================] - 0s 271us/step - loss: 0.3350 - acc: 1.0000\n",
      "Epoch 64/100\n",
      "59/59 [==============================] - 0s 712us/step - loss: 0.3268 - acc: 1.0000\n",
      "Epoch 65/100\n",
      "59/59 [==============================] - 0s 373us/step - loss: 0.3195 - acc: 1.0000\n",
      "Epoch 66/100\n",
      "59/59 [==============================] - 0s 305us/step - loss: 0.3132 - acc: 1.0000\n",
      "Epoch 67/100\n",
      "59/59 [==============================] - 0s 237us/step - loss: 0.3062 - acc: 1.0000\n",
      "Epoch 68/100\n",
      "59/59 [==============================] - 0s 271us/step - loss: 0.2999 - acc: 1.0000\n",
      "Epoch 69/100\n",
      "59/59 [==============================] - 0s 458us/step - loss: 0.2919 - acc: 1.0000\n",
      "Epoch 70/100\n",
      "59/59 [==============================] - 0s 271us/step - loss: 0.2858 - acc: 1.0000\n",
      "Epoch 71/100\n",
      "59/59 [==============================] - 0s 237us/step - loss: 0.2788 - acc: 1.0000\n",
      "Epoch 72/100\n",
      "59/59 [==============================] - 0s 458us/step - loss: 0.2724 - acc: 1.0000\n",
      "Epoch 73/100\n",
      "59/59 [==============================] - 0s 305us/step - loss: 0.2664 - acc: 1.0000\n",
      "Epoch 74/100\n",
      "59/59 [==============================] - 0s 288us/step - loss: 0.2605 - acc: 1.0000\n",
      "Epoch 75/100\n",
      "59/59 [==============================] - 0s 220us/step - loss: 0.2555 - acc: 1.0000\n",
      "Epoch 76/100\n",
      "59/59 [==============================] - 0s 288us/step - loss: 0.2489 - acc: 1.0000\n",
      "Epoch 77/100\n",
      "59/59 [==============================] - 0s 237us/step - loss: 0.2435 - acc: 1.0000\n",
      "Epoch 78/100\n",
      "59/59 [==============================] - 0s 559us/step - loss: 0.2381 - acc: 1.0000\n",
      "Epoch 79/100\n",
      "59/59 [==============================] - 0s 407us/step - loss: 0.2340 - acc: 1.0000\n",
      "Epoch 80/100\n",
      "59/59 [==============================] - 0s 288us/step - loss: 0.2276 - acc: 1.0000\n",
      "Epoch 81/100\n",
      "59/59 [==============================] - 0s 254us/step - loss: 0.2225 - acc: 1.0000\n",
      "Epoch 82/100\n",
      "59/59 [==============================] - 0s 237us/step - loss: 0.2174 - acc: 1.0000\n",
      "Epoch 83/100\n",
      "59/59 [==============================] - 0s 254us/step - loss: 0.2150 - acc: 1.0000\n",
      "Epoch 84/100\n",
      "59/59 [==============================] - 0s 390us/step - loss: 0.2080 - acc: 1.0000\n",
      "Epoch 85/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59/59 [==============================] - 0s 322us/step - loss: 0.2037 - acc: 1.0000\n",
      "Epoch 86/100\n",
      "59/59 [==============================] - 0s 373us/step - loss: 0.1993 - acc: 1.0000\n",
      "Epoch 87/100\n",
      "59/59 [==============================] - 0s 254us/step - loss: 0.1954 - acc: 1.0000\n",
      "Epoch 88/100\n",
      "59/59 [==============================] - 0s 305us/step - loss: 0.1908 - acc: 1.0000\n",
      "Epoch 89/100\n",
      "59/59 [==============================] - 0s 424us/step - loss: 0.1862 - acc: 1.0000\n",
      "Epoch 90/100\n",
      "59/59 [==============================] - 0s 492us/step - loss: 0.1823 - acc: 1.0000\n",
      "Epoch 91/100\n",
      "59/59 [==============================] - 0s 220us/step - loss: 0.1790 - acc: 1.0000\n",
      "Epoch 92/100\n",
      "59/59 [==============================] - 0s 678us/step - loss: 0.1750 - acc: 1.0000\n",
      "Epoch 93/100\n",
      "59/59 [==============================] - 0s 356us/step - loss: 0.1704 - acc: 1.0000\n",
      "Epoch 94/100\n",
      "59/59 [==============================] - 0s 305us/step - loss: 0.1670 - acc: 1.0000\n",
      "Epoch 95/100\n",
      "59/59 [==============================] - 0s 271us/step - loss: 0.1633 - acc: 1.0000\n",
      "Epoch 96/100\n",
      "59/59 [==============================] - 0s 271us/step - loss: 0.1599 - acc: 1.0000\n",
      "Epoch 97/100\n",
      "59/59 [==============================] - 0s 441us/step - loss: 0.1565 - acc: 1.0000\n",
      "Epoch 98/100\n",
      "59/59 [==============================] - 0s 254us/step - loss: 0.1534 - acc: 1.0000\n",
      "Epoch 99/100\n",
      "59/59 [==============================] - 0s 237us/step - loss: 0.1502 - acc: 1.0000\n",
      "Epoch 100/100\n",
      "59/59 [==============================] - 0s 288us/step - loss: 0.1468 - acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12e464a8>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,\n",
    "          Y_train,\n",
    "         batch_size=32,\n",
    "         nb_epoch=100,\n",
    "          shuffle=True,\n",
    "         verbose=1)\n",
    "\n",
    "# scores = model.evaluate(X_test, Y_test, verbose=0)\n",
    "# print(\"    : %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30  4 33 14 53 25 45 19 37 36 20  7 56 35  3  0 18 13 28 40  1 51 17  2\n",
      " 49 32 43 23 15 31  9 27 21  8  5 44 11 39 34 26 55 22  6 42 57 58 12 48\n",
      " 38 16 24 10 50 52 29 47 41 46 54]\n",
      "[0 1 0 0]\n",
      "[1 0 0 0]\n",
      "[1 0 0 0]\n",
      "[0 1 0 0]\n",
      "[1 0 0 0]\n",
      "[0 0 0 1]\n",
      "[0 0 0 1]\n",
      "[0 0 1 0]\n",
      "[0 0 0 1]\n",
      "[1 0 0 0]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x15413d30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.1629786  0.03455371 0.01280911 0.7896586 ]\n",
      " [0.08988053 0.01085441 0.8777125  0.02155259]\n",
      " [0.02883837 0.00460162 0.9603014  0.00625866]\n",
      " [0.03669275 0.00694022 0.94729877 0.00906824]\n",
      " [0.83210254 0.00500512 0.02724385 0.13564844]\n",
      " [0.03198569 0.00528028 0.95559573 0.00713832]\n",
      " [0.02154984 0.00441795 0.9691105  0.00492165]\n",
      " [0.8486096  0.00428994 0.02038169 0.1267187 ]\n",
      " [0.00166005 0.966735   0.00139928 0.03020566]\n",
      " [0.00187973 0.962965   0.00157546 0.0335798 ]\n",
      " [0.02328149 0.00451287 0.96689916 0.00530652]\n",
      " [0.00154226 0.96831536 0.00134114 0.02880121]\n",
      " [0.75100344 0.01289794 0.0347313  0.20136729]\n",
      " [0.16379537 0.03758655 0.013143   0.7854751 ]\n",
      " [0.00153397 0.96842515 0.00134466 0.02869626]\n",
      " [0.00155768 0.9682192  0.00140532 0.02881767]\n",
      " [0.82256263 0.00514246 0.0236318  0.1486631 ]\n",
      " [0.77866405 0.01112861 0.03947043 0.1707369 ]\n",
      " [0.00155494 0.9677935  0.00134637 0.02930517]\n",
      " [0.04027832 0.00688149 0.9432028  0.00963743]\n",
      " [0.04102962 0.0150934  0.9296304  0.01424661]\n",
      " [0.04004822 0.01522204 0.93050873 0.01422091]\n",
      " [0.04580662 0.00699648 0.93666345 0.0105335 ]\n",
      " [0.00199222 0.96194494 0.00168704 0.03437581]\n",
      " [0.8158932  0.00571202 0.03175239 0.1466425 ]\n",
      " [0.17337693 0.03707417 0.01330044 0.77624846]\n",
      " [0.03658082 0.00637743 0.9483491  0.00869269]\n",
      " [0.00187634 0.9629955  0.00153119 0.03359694]\n",
      " [0.17787308 0.03381233 0.01413852 0.77417606]\n",
      " [0.16626957 0.03174323 0.01420709 0.7877801 ]\n",
      " [0.0018289  0.96371853 0.00152741 0.03292524]\n",
      " [0.00162173 0.96785957 0.00146025 0.02905849]\n",
      " [0.19648457 0.02933088 0.0151385  0.759046  ]\n",
      " [0.8370838  0.00461412 0.02453778 0.1337642 ]\n",
      " [0.16970015 0.04218798 0.01485545 0.7732564 ]\n",
      " [0.00187083 0.963534   0.00159059 0.03300449]\n",
      " [0.80536014 0.0065754  0.01964205 0.16842242]\n",
      " [0.20690951 0.0338128  0.01794456 0.74133307]\n",
      " [0.00173609 0.96553135 0.0014817  0.03125094]\n",
      " [0.82567495 0.00535399 0.02039704 0.148574  ]\n",
      " [0.17745034 0.04546317 0.01757347 0.759513  ]\n",
      " [0.7607169  0.01159448 0.03039342 0.1972952 ]\n",
      " [0.03887135 0.00654523 0.9451797  0.00940368]\n",
      " [0.8402417  0.00426345 0.02045202 0.1350429 ]\n",
      " [0.80808556 0.00587939 0.03079079 0.15524429]\n",
      " [0.18028958 0.04441751 0.01946961 0.7558233 ]\n",
      " [0.18998154 0.04274795 0.01725854 0.750012  ]\n",
      " [0.18465869 0.03614619 0.02132607 0.75786906]\n",
      " [0.23392235 0.03570091 0.01949084 0.7108859 ]\n",
      " [0.7667757  0.01222945 0.04446216 0.17653257]\n",
      " [0.02818856 0.00841734 0.95521736 0.0081767 ]\n",
      " [0.00195126 0.9613633  0.00158718 0.03509837]\n",
      " [0.03097075 0.00890457 0.9514977  0.00862707]\n",
      " [0.7806758  0.01126973 0.0493446  0.15870984]\n",
      " [0.17236449 0.03400637 0.01660268 0.77702653]\n",
      " [0.21472348 0.04311634 0.02098299 0.7211772 ]\n",
      " [0.02889845 0.00555177 0.9588438  0.00670595]\n",
      " [0.00158086 0.9683726  0.00140046 0.02864605]\n",
      " [0.00175268 0.96540594 0.00151726 0.03132417]]\n"
     ]
    }
   ],
   "source": [
    "# use Matplotlib (don't ask)\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# encoded_imgs = encoder.predict(x_test)\n",
    "\n",
    "# decoded_imgs = decoder.predict(encoded_imgs)\n",
    "\n",
    "# Y_train = np_utils.to_categorical(labels, 4)\n",
    "\n",
    "prediction = model.predict(encoded_imgs)\n",
    "\n",
    "categorical_class = (prediction == prediction.max(axis=1, keepdims=True)).astype(int)\n",
    "# print(categorical_class)\n",
    "n = 10  # how many digits we will display\n",
    "indexes = np.random.permutation(59)\n",
    "print(indexes)\n",
    "# random.seed(59)\n",
    "# random.shuffle(imagePaths)\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    # print(x_test[i])\n",
    "    # prediction = model.predict(encoded_imgs[i])\n",
    "    # categorical_class = np_utils.categorical_probas_to_classes(prediction)\n",
    "    print(categorical_class[indexes[i]])\n",
    "    plt.imshow(x_test[indexes[i]].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(decoded_imgs[indexes[i]].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()\n",
    "print(prediction)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
